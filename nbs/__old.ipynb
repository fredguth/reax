{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpu'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| default_exp stores\n",
    "from functools import partial\n",
    "from itertools import zip_longest\n",
    "from operator import itemgetter\n",
    "from typing import Callable, NamedTuple, Tuple, Any, Optional, Union, TypeVar, Sequence, Mapping, List, Tuple, Dict, Hashable, Iterable, Type, cast, overload\n",
    "\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import lovely_jax as lj\n",
    "import lovely_tensors as lt\n",
    "import numpy as np\n",
    "import optax\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from lovely_numpy import lo as ln\n",
    "# from ./stores import Writable\n",
    "from torch.utils.data import DataLoader, default_collate\n",
    "import torch\n",
    "\n",
    "lt.monkey_patch()\n",
    "lj.monkey_patch()\n",
    "jax.default_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))\n",
    "\n",
    "def collate_dict(ds):\n",
    "    get = itemgetter(*ds.features)\n",
    "    def _f(b): return get(default_collate(b))\n",
    "    return _f\n",
    "\n",
    "class DataLoaders:\n",
    "    def __init__(self, *dls): self.train,self.valid = dls[:2]\n",
    "\n",
    "    @classmethod\n",
    "    def from_dd(cls, dd, batch_size, as_tuple=True, **kwargs):\n",
    "        f = collate_dict(dd['train'])\n",
    "        return cls(*get_dls(*dd.values(), bs=batch_size, collate_fn=f, **kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializer = Callable[[Sequence[int], Any], jax.Array]\n",
    "# Params = Mapping[str, Mapping[str, jax.Array]]\n",
    "# State = Mapping[str, Mapping[str, jax.Array]]\n",
    "\n",
    "# # Missing JAX types.\n",
    "# PRNGKey = jnp.ndarray  # pylint: disable=invalid-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRNGKey = jax.random.PRNGKey\n",
    "Tensor = Union[jax.Array, jnp.ndarray] # should include np.ndarray, torch.Tensor?\n",
    "PyTree = Union[Tensor,\n",
    "               Tuple['PyTree', ...],\n",
    "               List['PyTree'],\n",
    "               Dict[Hashable, 'PyTree'],\n",
    "               hk.Params, hk.State, optax.OptState,\n",
    "               None] #hope that it works with Haiku and Flax\n",
    "\n",
    "LossFn = Callable[[Tensor, Tensor], Tensor]\n",
    "ApplyFn = Callable[..., Tuple[Tensor, PyTree]] \n",
    "\n",
    "\n",
    "class Optimizer(NamedTuple):\n",
    "    state: optax.OptState # optax optimizer state\n",
    "    gradTransformer: optax.GradientTransformation # optax optimizer (e.g. Adam)\n",
    "\n",
    "class Learner(NamedTuple):\n",
    "    data: DataLoaders\n",
    "    model: Model\n",
    "    optimizer: Optimizer\n",
    "    loss_fn: LossFn\n",
    "    state: PyTree\n",
    "\n",
    "class Batch(NamedTuple):\n",
    "  input: np.ndarray   # [B, H, W, C]\n",
    "  target: np.ndarray  # [B]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(input=Array[500, 784] n=392000 x∈[-0.800, 2.057] μ=0.011 σ=1.006 gpu:0, target=Array[500] i32 x∈[0, 9] μ=4.402 σ=2.838 gpu:0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XMEAN,XSTD, BATCH_SIZE, NUM_CLASSES = 0.28,0.35, 500, 10\n",
    "\n",
    "tfm = transforms.Compose([transforms.PILToTensor(), transforms.Lambda(lambda x: x/255), transforms.Normalize(XMEAN, XSTD), transforms.Lambda(lambda x: torch.flatten(x))])\n",
    "ds = partial(torchvision.datasets.FashionMNIST,root=\"data\",download=True, transform = tfm)\n",
    "train_ds, valid_ds = ds(train=True), ds(train=False)\n",
    "tdl = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "vdl = DataLoader(valid_ds, batch_size=BATCH_SIZE)\n",
    "dls = DataLoaders(tdl, vdl)\n",
    "batch = Batch(*map(jnp.array, next(iter(dls.train))))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x:jnp.array) ->jnp.ndarray:\n",
    "  return hk.nets.MLP(output_sizes=[50,NUM_CLASSES])(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = hk.transform_with_state(forward)\n",
    "rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "params, state = jax.jit(network.init)(next(rng), batch.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "haiku._src.transform.TransformedWithState"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(network)\n",
    "hk.TransformedWithState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(NamedTuple):\n",
    "    rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "\n",
    "    @staticmethod\n",
    "    def from_haiku(\n",
    "        transformed: hk.TransformedWithState, # transformed haiku model\n",
    "        x: Tensor # example input (e.g. batch.input)\n",
    "        ):\n",
    "        init, apply = transformed\n",
    "        params, state = jax.jit(init)(next(Model.rng), x)\n",
    "        return Model(params=params, state=state, apply=apply)\n",
    "\n",
    "    params: PyTree  # model weights and biases\n",
    "    state: PyTree  # buffers (aka context) of the model (e.g. batch norm running mean)\n",
    "    apply: ApplyFn  # model pure inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.from_haiku(transformed=network, x=batch.input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function createCount() {\n",
    "\tconst { subscribe, set, update } = writable(0);\n",
    "\n",
    "\treturn {\n",
    "\t\tsubscribe,\n",
    "\t\tincrement: () => update(n => n + 1),\n",
    "\t\tdecrement: () => update(n => n - 1),\n",
    "\t\treset: () => set(0)\n",
    "\t};\n",
    "}\n",
    "\n",
    "export const count = createCount();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array gpu:0 0.146, {})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(model: Model, batch: Batch) -> Tensor:\n",
    "    (params, state, apply) = model\n",
    "    @jax.jit\n",
    "    def _evaluate(params, state, batch) -> Tensor:\n",
    "        logits, state = jax.jit(apply)(params, state, next(Model.rng), batch.input)\n",
    "        preds = jnp.argmax (logits, axis=-1)\n",
    "        return jnp.mean(preds == batch.target), state\n",
    "    result, state = _evaluate(params, state, batch)\n",
    "    \n",
    "evaluate(network.apply, params, state, next(rng), batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.541998863220215, {}, float)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loss_fn(apply: ApplyFn, params:hk.Params, state: hk.State, key:PRNGKey, batch: Batch) -> Tuple[float, hk.State]:\n",
    "    @jax.jit\n",
    "    def _loss(params, state,  key, batch)-> jnp.ndarray:\n",
    "        bs, *_ = batch.target.shape\n",
    "        logits, state = (apply)(params, state, key, batch.input)\n",
    "        return jnp.sum(optax.softmax_cross_entropy_with_integer_labels(logits, batch.target)/bs), state\n",
    "    loss_value, state =  _loss(params, state, key, batch)\n",
    "    return float(loss_value), state\n",
    "\n",
    "e, state = loss(network.apply, params, state, next(rng), batch)\n",
    "e, state, type(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer(NamedTuple):\n",
    "    opt: optax.GradientTransformation # optax optimizer (e.g. Adam)\n",
    "    state: optax.OptState # optax optimizer state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Optimizer(optax.adam(1e-3), optax.adam(1e-3).init(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientTransformation(init=<function chain.<locals>.init_fn>, update=<function chain.<locals>.update_fn>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(opt,opt_state) =  optimizer\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update(opt: optimizer, batch: Batch):\n",
    "    grads = jax.grad(loss_fn)(network.apply, params, state, next(rng), batch)\n",
    "    @jax.jit\n",
    "    def _update():\n",
    "        updates, opt_state = opt.update(grads, opt_state)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "    return (params, opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument '<function transform_with_state.<locals>.apply_fn at 0x7f1f989e1e50>' of type <class 'function'> is not a valid JAX type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _update(params, batch)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m, in \u001b[0;36m_update\u001b[0;34m(params, batch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m@jax\u001b[39m\u001b[39m.\u001b[39mjit\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update\u001b[39m(params: hk\u001b[39m.\u001b[39mParams, batch: Batch):\n\u001b[0;32m----> 3\u001b[0m     grads \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mgrad(loss_fn)(network\u001b[39m.\u001b[39;49mapply, params, state, \u001b[39mnext\u001b[39;49m(rng), batch)\n\u001b[1;32m      4\u001b[0m     updates, opt_state \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39mupdate(grads, opt_state)\n\u001b[1;32m      5\u001b[0m     params \u001b[39m=\u001b[39m optax\u001b[39m.\u001b[39mapply_updates(params, updates)\n",
      "    \u001b[0;31m[... skipping hidden 5 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.miniconda3/envs/jaxai2/lib/python3.9/site-packages/jax/_src/dispatch.py:624\u001b[0m, in \u001b[0;36mcheck_arg\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_arg\u001b[39m(arg):\n\u001b[1;32m    623\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(arg, core\u001b[39m.\u001b[39mTracer) \u001b[39mor\u001b[39;00m _valid_jaxtype(arg)):\n\u001b[0;32m--> 624\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mArgument \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00marg\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(arg)\u001b[39m}\u001b[39;00m\u001b[39m is not a valid \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    625\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mJAX type.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument '<function transform_with_state.<locals>.apply_fn at 0x7f1f989e1e50>' of type <class 'function'> is not a valid JAX type."
     ]
    }
   ],
   "source": [
    "_update(params, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = TypeVar(\"K\")\n",
    "V = TypeVar(\"V\")\n",
    "T = TypeVar(\"T\")\n",
    "U = TypeVar(\"U\")\n",
    "PyTreeDef = type(jax.tree_util.tree_structure(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pFlat, pDef = jax.tree_util.tree_flatten(params)\n",
    "a: jax.Array = pFlat[0]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "network.init(next(rng), jnp.ones([BATCH_SIZE, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "params, buffers = network.init(next(rng), jnp.ones([BATCH_SIZE, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(buffers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(NamedTuple):\n",
    "    apply: Callable # model inference function\n",
    "    params: hk.Params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
