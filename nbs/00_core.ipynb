{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> This is the core of the `Reax` lib. \n",
    "\n",
    "Here we define the major abstractions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_MEM_FRACTION=0.2\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "%env XLA_PYTHON_CLIENT_MEM_FRACTION=0.2\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|export\n",
    "from functools import partial\n",
    "from typing import (Callable, Dict, Hashable, List, Mapping, NamedTuple,\n",
    "                    Optional, Sequence, Tuple, Union)\n",
    "\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import lovely_jax as lj\n",
    "import numpy as np\n",
    "import optax\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "lj.monkey_patch()\n",
    "jax.default_backend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in `miniai`, we wil be using the `FashionMnist` Dataset for demonstration.   `Reax` is not intended to be a complete library, the `data` module is just a copy from [miniai]() to make it work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from reax.data import DataLoaders, Batch, Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(input=Array[500, 784] n=392000 x∈[-0.800, 2.057] μ=0.011 σ=1.006 gpu:0, target=Array[500] i32 x∈[0, 9] μ=4.402 σ=2.838 gpu:0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "XMEAN,XSTD, BATCH_SIZE, NUM_CLASSES = 0.28,0.35, 500, 10\n",
    "\n",
    "tfm = transforms.Compose([transforms.PILToTensor(), \n",
    "                          transforms.Lambda(lambda x: x/255), transforms.Normalize(XMEAN, XSTD), \n",
    "                          transforms.Lambda(lambda x: torch.flatten(x))])\n",
    "ds = partial(torchvision.datasets.FashionMNIST,root=\"data\",download=True, transform = tfm)\n",
    "train_ds, valid_ds = ds(train=True), ds(train=False)\n",
    "tdl = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "vdl = DataLoader(valid_ds, batch_size=BATCH_SIZE)\n",
    "dls = DataLoaders(tdl, vdl)\n",
    "batch = Batch(*map(jnp.array, next(iter(dls.train))))\n",
    "batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "Have you noticed how tensors are printed? This is [lovely-jax](https://xl0.github.io/lovely-jax/), the wonderful library that makes the JAX array representation more friendly. \n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic [Haiku](https://dm-haiku.readthedocs.io/) object to represent a model is a [TransformedWithState](https://dm-haiku.readthedocs.io/en/latest/api.html#transformedwithstate).  It represents a `function` or `module` that has been transformed by a `hk.transform` function.  Here we are using `hk.transform_with_state` which is the superset of the transform functions.  \n",
    "\n",
    "State in the `Haiku` lingo means everything that make your original `Callable` not a pure function.  It is the context or state.  Somoe common `DNN` modules like `batch_norm`can keep some `state` to perform its work.  `State`, `Buffers` and `Context` are common names for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "haiku._src.transform.TransformedWithState"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward(x:jnp.array) ->jnp.ndarray:\n",
    "  return hk.nets.MLP(output_sizes=[50,NUM_CLASSES])(x) # todo: remove NUM_CLASSES dependency\n",
    "network = hk.transform_with_state(forward)\n",
    "type(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `Reax`, a `Model` is an immutable object. [PyTrees](https://jax.readthedocs.io/en/latest/pytrees.html) are JAX datastructures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "PyTree = Union[\n",
    "    Tensor, Tuple[\"PyTree\", ...], List[\"PyTree\"], Dict[Hashable, \"PyTree\"], hk.Params, hk.State, optax.OptState, None\n",
    "]  # I hope that with this definition it will work in  Haiku and Flax\n",
    "\n",
    "ApplyFn = Callable[..., Tuple[Tensor, PyTree]] # returns result and state (aka buffers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|exports\n",
    "class Model(NamedTuple):\n",
    "    params: PyTree # the models parameters, weights and biases\n",
    "    state: PyTree  # the model auxiliary state, e.g. batchnorm buffers\n",
    "    apply: ApplyFn # the model forward pass function\n",
    "    input_shape: Tuple[int, ...] # the shape of the input, used to infer the model output shape\n",
    "\n",
    "    rng = hk.PRNGSequence(42) # random number generator\n",
    "\n",
    "    @staticmethod\n",
    "    def from_haiku(\n",
    "        transformed: hk.TransformedWithState,       # transformed haiku model\n",
    "        x: Tensor                                   # example input (e.g. batch.input)\n",
    "    ):\n",
    "        ''' Create a Model from a Haiku Transformed object and an example input.'''\n",
    "        init, apply = transformed\n",
    "        params, state = jax.jit(init)(next(Model.rng), x)\n",
    "        return Model(params=params, state=state, apply=apply, input_shape=x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(params={'mlp/~/linear_0': {'b': Array[50] \u001b[38;2;127;127;127mall_zeros\u001b[0m gpu:0, 'w': Array[784, 50] n=39200 x∈[-0.071, 0.071] μ=0.000 σ=0.032 gpu:0}, 'mlp/~/linear_1': {'b': Array[10] \u001b[38;2;127;127;127mall_zeros\u001b[0m gpu:0 [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], 'w': Array[50, 10] n=500 x∈[-0.276, 0.270] μ=-0.001 σ=0.121 gpu:0}}, state={}, apply=<function transform_with_state.<locals>.apply_fn at 0x7fb8f8324280>, input_shape=(500, 784))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Model.from_haiku(transformed=network, x=batch.input)\n",
    "m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep us sane and improve the model representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "import fastcore.all as fc\n",
    "from tabulate import tabulate\n",
    "from reax.utils import str_tree\n",
    "# the tabulate package is also used by Haiku in its hk.experimental methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "@fc.patch\n",
    "def __repr__(self:Model)->str:\n",
    "    table = [[\"Params\", \"State\"],[str_tree(self.params), str_tree(self.state)]]\n",
    "    return f\"{self.__class__.__name__}:\\n{tabulate(table, headers='firstrow', tablefmt='grid')}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model:\n",
       "+---------------------------------------------+---------+\n",
       "| Params                                      | State   |\n",
       "+=============================================+=========+\n",
       "| mlp/~/linear_0:                             | {}      |\n",
       "|   b: all_zeros                              |         |\n",
       "|   w: x∈[-0.071, 0.071] μ=-9.844e-05 σ=0.032 |         |\n",
       "| mlp/~/linear_1:                             |         |\n",
       "|   b: all_zeros                              |         |\n",
       "|   w: x∈[-0.275, 0.279] μ=-0.002 σ=0.123     |         |\n",
       "+---------------------------------------------+---------+"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Model.from_haiku(transformed=network, x=batch.input)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "@fc.patch\n",
    "def __str__(self:Model) -> str:\n",
    "    s1 = hk.experimental.tabulate(self.apply,\n",
    "            columns=[\"input\", \"module\", \"owned_params\", \"output\", \"params_size\"])(jnp.ones(self.input_shape))\n",
    "    s2 = '\\n'.join(self.__repr__().split('\\n')[1:])\n",
    "    return f\"{s1}\\n{s2}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "| Input        | Module                  | Module params   | Output      |   Param count |\n",
      "+==============+=========================+=================+=============+===============+\n",
      "| f32[500,784] | mlp (MLP)               |                 | f32[500,10] |        39,760 |\n",
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "| f32[500,784] | mlp/~/linear_0 (Linear) | w: f32[784,50]  | f32[500,50] |        39,250 |\n",
      "|              |  └ mlp (MLP)            | b: f32[50]      |             |               |\n",
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "| f32[500,50]  | mlp/~/linear_1 (Linear) | w: f32[50,10]   | f32[500,10] |           510 |\n",
      "|              |  └ mlp (MLP)            | b: f32[10]      |             |               |\n",
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "+---------------------------------------------+---------+\n",
      "| Params                                      | State   |\n",
      "+=============================================+=========+\n",
      "| mlp/~/linear_0:                             | {}      |\n",
      "|   b: all_zeros                              |         |\n",
      "|   w: x∈[-0.071, 0.071] μ=-9.844e-05 σ=0.032 |         |\n",
      "| mlp/~/linear_1:                             |         |\n",
      "|   b: all_zeros                              |         |\n",
      "|   w: x∈[-0.275, 0.279] μ=-0.002 σ=0.123     |         |\n",
      "+---------------------------------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Reactivity (Model Store)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we will start to play with reactivity.  In `fastai` (also in Keras, vanilla PyTorch, etc) there is the concept of `Callbacks`.  It is the way to be notified when something of interest happens. \n",
    "\n",
    "> Don't nudge me, let me __call you back__ when I have something for you!\n",
    "\n",
    "In general, you will need a callback only during training, after all, it is when your `things` change.  The model, the hyperparameters, the metrics, etc.\n",
    "\n",
    "The __fastai/miniai__ `Learner` is an `Observable` and you can hold multiple callbacks. Every callback keep its state in the Learner object. You can have callbacks for metrics, for logging and saving the training process... callbacks that depend on other callbacks! That is why there is that ... shall I say... __ugly__ `order` property in the `Callback`class.\n",
    "\n",
    "`Reax` is just an experiment on how to handle this reactivity in another way.  Maybe it will prove itself too bloated... or not. I decided to do it in `JAX/Haiku` to force a `functional programming` perspective.\n",
    "\n",
    "The basic abstraction in  `Reax` are `stores`, observables that hold any value. We could have used [RxPy] which is an incredible package. But its superpowers may be too much for what we need. That is why I took inspiration from the `Svelte` JS framework to create `stores` (it became its own package, [Sveltish](https://fredguth.github.io/sveltish)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "from reax.stores import Writable, Notifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `ModelStore` is just a `Writable` store that holds values of type `Model`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class ModelStore(Writable[Model]):\n",
    "    ''' A Model store. Custom Writable store'''\n",
    "    def __init__(self,\n",
    "                initial_value: Model, # Initial value of the store\n",
    "            ) -> None:\n",
    "        start: Notifier = lambda x: None # we won't need a Start/Stop Notifier\n",
    "        super().__init__(initial_value, start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving the ModelStore representation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also may improve its representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "@fc.patch\n",
    "def __repr__(self:ModelStore) -> str:\n",
    "    params, state, apply, shape = self.value\n",
    "    table = [[\"Params\", \"State\", \"Callbacks\"],[str_tree(params), str_tree(state), [f\"{s}\\n\" for s in self.subscribers]]]\n",
    "    table = [[\"Params\", \"State\", \"Callbacks\"],\n",
    "                [str_tree(m.params), str_tree(m.state), yaml.dump([{i:str(f)} for i,f in enumerate(self.subscribers)])]]\n",
    "    return f\"{self.__class__.__name__}:\\n{tabulate(table, headers='firstrow', tablefmt='grid')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelStore:\n",
       "+---------------------------------------------+---------+-------------+\n",
       "| Params                                      | State   | Callbacks   |\n",
       "+=============================================+=========+=============+\n",
       "| mlp/~/linear_0:                             | {}      | []          |\n",
       "|   b: all_zeros                              |         |             |\n",
       "|   w: x∈[-0.071, 0.071] μ=-9.844e-05 σ=0.032 |         |             |\n",
       "| mlp/~/linear_1:                             |         |             |\n",
       "|   b: all_zeros                              |         |             |\n",
       "|   w: x∈[-0.275, 0.279] μ=-0.002 σ=0.123     |         |             |\n",
       "+---------------------------------------------+---------+-------------+"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms = ModelStore(m)\n",
    "ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "@fc.patch\n",
    "def __str__(self:ModelStore) -> str:\n",
    "    columns=[\"input\", \"module\", \"owned_params\", \"output\", \"params_size\"]\n",
    "    s = hk.experimental.tabulate(self.value.apply, columns=columns)(jnp.ones(self.value.input_shape))\n",
    "    r=  f\"{s}\\n\"\n",
    "    s = '\\n'.join(self.__repr__().split('\\n')[1:])\n",
    "    r+= f\"{s}\"\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "| Input        | Module                  | Module params   | Output      |   Param count |\n",
      "+==============+=========================+=================+=============+===============+\n",
      "| f32[500,784] | mlp (MLP)               |                 | f32[500,10] |        39,760 |\n",
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "| f32[500,784] | mlp/~/linear_0 (Linear) | w: f32[784,50]  | f32[500,50] |        39,250 |\n",
      "|              |  └ mlp (MLP)            | b: f32[50]      |             |               |\n",
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "| f32[500,50]  | mlp/~/linear_1 (Linear) | w: f32[50,10]   | f32[500,10] |           510 |\n",
      "|              |  └ mlp (MLP)            | b: f32[10]      |             |               |\n",
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "+---------------------------------------------+---------+-------------+\n",
      "| Params                                      | State   | Callbacks   |\n",
      "+=============================================+=========+=============+\n",
      "| mlp/~/linear_0:                             | {}      | []          |\n",
      "|   b: all_zeros                              |         |             |\n",
      "|   w: x∈[-0.071, 0.071] μ=-9.844e-05 σ=0.032 |         |             |\n",
      "| mlp/~/linear_1:                             |         |             |\n",
      "|   b: all_zeros                              |         |             |\n",
      "|   w: x∈[-0.275, 0.279] μ=-0.002 σ=0.123     |         |             |\n",
      "+---------------------------------------------+---------+-------------+\n"
     ]
    }
   ],
   "source": [
    "print(ms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `callback` is any `Callable` that you pass on `subscribe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: callback 1\n"
     ]
    }
   ],
   "source": [
    "u1 = ms.subscribe(lambda x: print(\"1: callback 1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A change in the store value, triggers all callbacks subscribed to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: callback 1\n"
     ]
    }
   ],
   "source": [
    "m = ms.get()\n",
    "ms.set(Model(**(m._asdict()|{\"state\": {'a': 1, 'b': 2}})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can have different `stores` for different things.  For example, this is a simpler one to deal with the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "class Optimizer(NamedTuple):\n",
    "    state: optax.OptState\n",
    "    apply: Callable\n",
    "\n",
    "OptimizerStore = Writable[Optimizer]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, we will use [Optax](https://optax.readthedocs.io/), which is a good companion for `Haiku`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Optimizer(state=(EmptyState(), EmptyState()), apply=<function chain.<locals>.update_fn at 0x7fb8f80ec940>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_tfm = optax.sgd(1e-3)\n",
    "apply = grad_tfm.update\n",
    "optState = grad_tfm.init(m.params) # you initialize the optimizer with the model params\n",
    "optimizer = Optimizer(state=optState, apply=apply)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "callback 2: Optimizer(state=(EmptyState(), EmptyState()), apply=<function chain.<locals>.update_fn at 0x7fb8f80ec940>)\n"
     ]
    }
   ],
   "source": [
    "os= OptimizerStore(optimizer)\n",
    "u2 = os.subscribe(lambda x: print(f\"callback 2: {x}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "callback 2: Optimizer(state=(ScaleByAdamState(count=Array i32 gpu:0 0, mu={'mlp/~/linear_0': {'b': Array[50] \u001b[38;2;127;127;127mall_zeros\u001b[0m gpu:0, 'w': Array[784, 50] \u001b[38;2;127;127;127mall_zeros\u001b[0m gpu:0}, 'mlp/~/linear_1': {'b': Array[10] \u001b[38;2;127;127;127mall_zeros\u001b[0m gpu:0 [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], 'w': Array[50, 10] \u001b[38;2;127;127;127mall_zeros\u001b[0m gpu:0}}, nu={'mlp/~/linear_0': {'b': Array[50] \u001b[38;2;127;127;127mall_zeros\u001b[0m gpu:0, 'w': Array[784, 50] \u001b[38;2;127;127;127mall_zeros\u001b[0m gpu:0}, 'mlp/~/linear_1': {'b': Array[10] \u001b[38;2;127;127;127mall_zeros\u001b[0m gpu:0 [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], 'w': Array[50, 10] \u001b[38;2;127;127;127mall_zeros\u001b[0m gpu:0}}), EmptyState()), apply=<function chain.<locals>.update_fn at 0x7fb8f80ecd30>)\n"
     ]
    }
   ],
   "source": [
    "grad_tf2 = optax.adam(1e-4)\n",
    "optState2 = grad_tf2.init(m.params)\n",
    "os.set(Optimizer(state=optState2, apply=grad_tf2.update))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up... you should remember to unsubscribe when you are done with a store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u1(), u2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cb 1:\n",
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "| Input        | Module                  | Module params   | Output      |   Param count |\n",
      "+==============+=========================+=================+=============+===============+\n",
      "| f32[500,784] | mlp (MLP)               |                 | f32[500,10] |        39,760 |\n",
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "| f32[500,784] | mlp/~/linear_0 (Linear) | w: f32[784,50]  | f32[500,50] |        39,250 |\n",
      "|              |  └ mlp (MLP)            | b: f32[50]      |             |               |\n",
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "| f32[500,50]  | mlp/~/linear_1 (Linear) | w: f32[50,10]   | f32[500,10] |           510 |\n",
      "|              |  └ mlp (MLP)            | b: f32[10]      |             |               |\n",
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "+-----------------------------------------+---------+\n",
      "| Params                                  | State   |\n",
      "+=========================================+=========+\n",
      "| mlp/~/linear_0:                         | {}      |\n",
      "|   b: all_zeros                          |         |\n",
      "|   w: x∈[-0.071, 0.071] μ=-0.000 σ=0.032 |         |\n",
      "| mlp/~/linear_1:                         |         |\n",
      "|   b: all_zeros                          |         |\n",
      "|   w: x∈[-0.280, 0.278] μ=-0.008 σ=0.123 |         |\n",
      "+-----------------------------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "m = Model.from_haiku(transformed=network, x=batch.input)\n",
    "ms = ModelStore(m)\n",
    "u1 = ms.subscribe(lambda x: print(f\"cb 1:\\n{x}\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we arrived at the Training, the  `core` of the `core`  ```¯\\_(ツ)_/¯```\n",
    "\n",
    "Here is where we will most need callbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in `fastai`, we create a `Learner` class that will deal with the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner:\n",
       "+-----------------+-----------------+-----------------+-----------------+\n",
       "|           Model |     DataLoaders |          LossFn |       Optimizer |\n",
       "+=================+=================+=================+=================+\n",
       "| 140432412740432 | 140432415838800 | 140436291828464 | 140432412267040 |\n",
       "+-----------------+-----------------+-----------------+-----------------+"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|export\n",
    "LossFn = Callable[[Tensor, Tensor], Tensor] # per example loss function\n",
    "class Learner:\n",
    "    '''Basic class for handling the training loop.'''\n",
    "    def __init__(self, model:ModelStore, dls: DataLoaders, loss_func: LossFn, optimizer: OptimizerStore) -> None:\n",
    "        # keeping fastai orderhere. I would prefer: dls, model, optimizer, loss_func, which seems more natural to me.\n",
    "        fc.store_attr()\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}:\\n{self}\"\n",
    "    def __str__(self) -> str:\n",
    "        table = [[\"Model\", \"DataLoaders\", \"LossFn\", \"Optimizer\"],[id(self.model), id(self.dls), id(self.loss_func), id(self.optimizer)]]\n",
    "        return tabulate(table, headers='firstrow', tablefmt='grid')\n",
    "\n",
    "learner = Learner(model=ms, dls=dls, loss_func=optax.softmax_cross_entropy_with_integer_labels, optimizer=os)\n",
    "learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learner itself, is not a store, but holds different stores for different aspects of the training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a `ModelStore`, an `OptimizerStore`... it is only missing the most important thing we want to __observe__... the training loop itself. We need a `TrainingStore`.\n",
    "\n",
    "But for that... let's first examine what we need.  Let's take a look in the __training loop__:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The anatomy of a training loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# pseudo-code\n",
    "\n",
    "def fit(epochs: int)->None:\n",
    "    '''Train the model for a number of epochs.'''\n",
    "    # before fit\n",
    "    for epoch in range(epochs):\n",
    "        # is_training\n",
    "        one_epoch(dls.train) # train for one epoch\n",
    "        # is_validating\n",
    "        one_epoch(dls.valid) # validate for one epoch\n",
    "        # should halt epochs?\n",
    "    # after fit\n",
    "\n",
    "def one_epoch(dl)->None:\n",
    "    '''Train or validate for one epoch.'''\n",
    "    # before epoch\n",
    "    for batch_n, batch in enumerate(dl): \n",
    "        one_batch(batch_n, batch)\n",
    "        # should halt batches?\n",
    "    # after epoch\n",
    "\n",
    "def one_batch(batch_n: int, batch: Batch)->None:\n",
    "    '''Train or validate for one batch.'''\n",
    "    # before batch\n",
    "    predict(...) # preds\n",
    "    evaluate(...)# loss\n",
    "    update model(...) if is_training\n",
    "    # after batch\n",
    "````"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `TrainingStore` shall tell us where we are in the training loop and some information relevant at this point.\n",
    "\n",
    ">  I am `training`, `epoch` 5, `iteration` 345, after `evaluate` with certain `current loss`.\n",
    "\n",
    "\n",
    "Another aspect is that it seems it should be a `Readable` store, afterall, we don't want any callback being able to change information like:\n",
    "`in which batch of which epoch am I?`\n",
    "\n",
    "Exceptionally, we want to tell the `TrainingStore` to halt.\n",
    "\n",
    "Let's start with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "class TrainingState(NamedTuple):\n",
    "\n",
    "    last: Dict                      # last event that happened {'event': {payload}),\n",
    "                                    # eg. {'before_batch': {'iter': 345}}\n",
    "    epochs: int                     # number of epochs to fit\n",
    "    epoch: int                      # current epoch\n",
    "    step: int                       # current step, since the beginning of the training\n",
    "    iter: int                       # current batch number, since beggining of the epoch\n",
    "    batch: Optional[Batch]          # current batch instance or None (if training hasn't started yet)\n",
    "    is_running: bool=False          # True if running (training/validation), False if stopped\n",
    "    is_training: bool=False         # True if training is in progress\n",
    "    is_validating: bool=False       # True if evaluation is in progress\n",
    "    should_halt: bool=False         # True if should stop, False otherwise\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}:\\n{self}\"\n",
    "    def __str__(self) -> str:\n",
    "        s = \"\"\n",
    "        for (start,end) in [(0,6),(6,10)]:\n",
    "            keys = list(t._asdict().keys())[start:end]\n",
    "            values = [t._asdict()[key] for key in keys]\n",
    "            s+= f\"{tabulate([values], headers=keys, tablefmt='grid')}\\n\"\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingState:\n",
       "+-------------------+----------+---------+--------+--------+---------+\n",
       "| last              |   epochs |   epoch |   step |   iter | batch   |\n",
       "+===================+==========+=========+========+========+=========+\n",
       "| {'created': None} |        0 |       0 |      0 |      0 |         |\n",
       "+-------------------+----------+---------+--------+--------+---------+\n",
       "+--------------+---------------+-----------------+---------------+\n",
       "| is_running   | is_training   | is_validating   | should_halt   |\n",
       "+==============+===============+=================+===============+\n",
       "| False        | False         | False           | False         |\n",
       "+--------------+---------------+-----------------+---------------+"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = TrainingState(last={'created':None}, epochs=0, epoch=0, step=0, iter=0, batch=None)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "class TrainingStore(Writable[TrainingState]):\n",
    "    ''' A store that keeps tracking of the training loop state'''\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}:\\n{self}\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        state = list(self.value._asdict().items())\n",
    "        state_t = list(zip(*state))\n",
    "        cbs = [(f\"{i}:\", v) for i, v in enumerate(self.subscribers)]\n",
    "        cbs_t = list(zip(*cbs))\n",
    "        table = list(itertools.zip_longest(*state_t,*cbs_t))\n",
    "        return tabulate(table, headers=['','State','', 'Calbacks'], tablefmt='grid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TrainingStore representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# a = [(\"A\", \"B\", \"C\"), (1,2,3)]\n",
    "# b = [(\"D\", \"E\", None), (4,5,None)]\n",
    "a = [(\"A\", 1), [\"B\", 2], [\"C\", 3]]\n",
    "b = [[\"D\", 4], [\"E\", 5]]\n",
    "c = list(zip(*a))\n",
    "d = list(zip(*b))\n",
    "table = list(itertools.zip_longest(*c,*d))\n",
    "print(tabulate(table, headers=['','H1','', \"H2\"], tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "a = [[\"A\", 1], [\"B\", 2], [\"C\", 3]]\n",
    "b = []\n",
    "c = list(zip(*a))\n",
    "d = list(zip(*b))\n",
    "table = list(itertools.zip_longest(*c,*d))\n",
    "print(tabulate(table, headers=['','H1','', \"H2\"], tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "a = [('epoch', 0), ('step', 0), ('batch_n', 0), ('batch', None), ('metrics', None), ('last_event', None), ('is_training', False), ('should_halt', False)]\n",
    "b = [('0:', lambda:None)]\n",
    "c = list(zip(*a))\n",
    "d = list(zip(*b))\n",
    "table = list(itertools.zip_longest(*c,*d))\n",
    "print(tabulate(table, headers=['','H1','', \"H2\"], tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "@fc.patch\n",
    "def __repr__(self: TrainingStore) -> str:\n",
    "        return f\"{self.__class__.__name__}:\\n{self}\"\n",
    "@fc.patch\n",
    "def __str__(self: TrainingStore) -> str:\n",
    "    state = list(self.value._asdict().items())\n",
    "    state_t = list(zip(*state))\n",
    "    cbs = [(f\"{i}:\", v) for i, v in enumerate(self.subscribers)]\n",
    "    cbs_t = list(zip(*cbs))\n",
    "    table = list(itertools.zip_longest(*state_t,*cbs_t))\n",
    "    return tabulate(table, headers=['','State','', 'Calbacks'], tablefmt='grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ts = TrainingStore(t, lambda x:None)\n",
    "u4 = ts.subscribe(lambda x: print(f\"callback 4:\\n {x}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "unsubs = []\n",
    "for i in range(12):\n",
    "    u = ts.subscribe(lambda x: print(f\"callback: {i}\"))\n",
    "    unsubs.append(u)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for u in unsubs: u()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "list(ts.value._asdict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "LossFn = Callable[[Tensor, Tensor], Tensor] # per example loss function\n",
    "class Learner:\n",
    "    '''Basic class for handling the training loop.'''\n",
    "    def __init__(self, model:ModelStore, dls: DataLoaders, loss_func: LossFn, optimizer: OptimizerStore) -> None:\n",
    "        # keeping fastai orderhere. I would prefer: dls, model, optimizer, loss_func, which seems more natural to me.\n",
    "        fc.store_attr()\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}:\\n{self}\"\n",
    "    def __str__(self) -> str:\n",
    "        table = [[\"Model\", \"DataLoaders\", \"LossFn\", \"Optimizer\"],[id(self.model), id(self.dls), id(self.loss_func), id(self.optimizer)]]\n",
    "        return tabulate(table, headers='firstrow', tablefmt='grid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class TrainingState:\n",
    "    def __init__(self, *,\n",
    "        epochs: int,                     # number of epochs to fit\n",
    "        epoch: int,                      # current epoch\n",
    "        step: int,                       # current step, since the beginning of the training\n",
    "        iter: int,                       # current batch number, since beggining of the epoch\n",
    "        batch: Optional[Batch],          # current batch instance or None (if training hasn't started yet)\n",
    "        last: Dict=None,                 # last event that happened {'event': {payload}),\n",
    "                                         # eg. {'before_batch': {'iter': 345}}\n",
    "        is_running: bool=False,          # True if running (training/validation), False, if stopped\n",
    "        is_training: bool=False,         # True if training is in progress\n",
    "        is_validating: bool=False,       # True if evaluation is in progress\n",
    "        should_halt: bool=False,         # True if should stop, False otherwise\n",
    "    ) -> None: fc.store_attr()\n",
    "    def as_dict(self):\n",
    "        return self.__stored_args__\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}:\\n{self}\"\n",
    "    def __str__(self) -> str:\n",
    "        return tabulate(list(self.__dict__.items())[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class T4:\n",
    "    def __init__(self, *, a: int, b: float = 1):\n",
    "        fc.store_attr()\n",
    "        \n",
    "t = T4(a=3)\n",
    "assert t.a==3 and t.b==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class TrainingStore(Writable[TrainingState]):\n",
    "    ''' A store that keeps tracking of the training loop state'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "@fc.patch\n",
    "def __str__(self: TrainingStore) -> str:\n",
    "    return str(self.value)\n",
    "    # state = list(self.value.__dict__.items())\n",
    "    # state_t = list(zip(*state))\n",
    "    # cbs = [(f\"{i}:\", v) for i, v in enumerate(self.subscribers)]\n",
    "    # cbs_t = list(zip(*cbs))\n",
    "    # table = list(itertools.zip_longest(*state_t,*cbs_t))\n",
    "    # return tabulate(table, headers=['','State','', 'Calbacks'], tablefmt='grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "@fc.patch\n",
    "def __init__(self:Learner, model:ModelStore, dls: DataLoaders, loss_func: LossFn, optimizer: OptimizerStore) -> None:\n",
    "    # keeping fastai orderhere. I would prefer: dls, model, optimizer, loss_func, which seems more natural to me.\n",
    "    fc.store_attr()\n",
    "    self.store = TrainingStore(TrainingState(epochs=0, epoch=0, step=0, iter=0, batch=None))\n",
    "    self.watch = list(learner.store.value.__dict__.keys())[1:] # attributes to watch for changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "@fc.patch\n",
    "def __settr__(self:Learner, name, value) -> None:\n",
    "    print ('name:', name)\n",
    "    if name in self.watch:\n",
    "        print('watcha!')\n",
    "    self.super().__setattr__(name, value)\n",
    "\n",
    "@fc.patch\n",
    "def __str__(self:Learner) -> str:\n",
    "    return f\"{self.__dict__}\"\n",
    "    # table = [[\"Model\", \"DataLoaders\", \"LossFn\", \"Optimizer\"],[id(self.model), id(self.dls), id(self.loss_func), id(self.optimizer)]]\n",
    "    # table =  tabulate(table, headers='firstrow', tablefmt='grid')\n",
    "    # return f\"{table}\\n ... \\n {self.__dict__}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "LossFn = Callable[[Tensor, Tensor], Tensor] # per example loss function\n",
    "class Learner:\n",
    "    '''Basic class for handling the training loop.'''\n",
    "    def __init__(self, model:ModelStore, dls: DataLoaders, loss_func: LossFn, optimizer: OptimizerStore) -> None:\n",
    "        # keeping fastai orderhere. I would prefer: dls, model, optimizer, loss_func, which seems more natural to me.\n",
    "        fc.store_attr()\n",
    "        self.store = TrainingStore(TrainingState(epochs=0, epoch=0, step=0, iter=0, batch=None))\n",
    "        self.watch = list(learner.store.value.__dict__.keys())[1:] # attributes to watch for changes\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}:\\n{self}\"\n",
    "    # def __str__(self) -> str:\n",
    "    #     r = f\"{list(self.__dict__.keys())}\\n\"\n",
    "    #     table = [[\"Model\", \"DataLoaders\", \"LossFn\", \"Optimizer\"],[id(self.model), id(self.dls), id(self.loss_func), id(self.optimizer)]]\n",
    "    #     return r+tabulate(table, headers='firstrow', tablefmt='grid')\n",
    "    def __setattr__(self, k,v) -> None:\n",
    "        if hasattr(self, 'watch') and k in self.watch:\n",
    "            new_value = self.store.value.as_dict()|{k:v}\n",
    "            self.store.set(TrainingState(**new_value))\n",
    "        super().__setattr__(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "learner = Learner(model=ms, dls=dls, loss_func=optax.softmax_cross_entropy_with_integer_labels, optimizer=os)\n",
    "learner.x = 1\n",
    "learner.epoch = 1\n",
    "learner.iter = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "a = NamedTuple(\"a\", [(\"n\", int)])\n",
    "a.n = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "a.x = 3\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Bunch:\n",
    "    __init__ = lambda self, **kw: setattr(self, '__dict__', kw)\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}({self.__dict__!r})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "a = Bunch(n=2,x=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "a.y=10\n",
    "a.iter = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "a.__dict__|{'y':12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "setattr(a, 'z', 30)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# class with_interceptor:\n",
    "#     def __init__(self, nm): self.nm = nm\n",
    "#     def __call__(self, f):\n",
    "#         print('intercepting....')\n",
    "#         print(f)\n",
    "#         # print(f'args: {args}')\n",
    "#         # print(f'kwargs: {kwargs}')\n",
    "#         return f\n",
    "#     def __setattr__(self, k,v) -> None:\n",
    "#         print('i.__setattr__:', (k,v))\n",
    "#         super().__setattr__(k,v)\n",
    "\n",
    "# class DummyCls:\n",
    "\n",
    "#     @with_interceptor\n",
    "#     def dummy_fn(self, x):\n",
    "#         x = 1\n",
    "#         print('dummy')\n",
    "\n",
    "# a = DummyCls()\n",
    "# a.dummy_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# def make_pretty(func):\n",
    "#     def inner(*args, **kwargs):\n",
    "#         print(\"I got decorated\")\n",
    "#         func(*args, **kwargs)\n",
    "#     return inner\n",
    "\n",
    "\n",
    "# @make_pretty\n",
    "# def ordinary(x):\n",
    "#     print(\"I am ordinary\")\n",
    "\n",
    "\n",
    "# ordinary(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class with_cbs:\n",
    "    def __init__(self, nm): self.nm = nm\n",
    "    def __call__(self, f):\n",
    "        def _f(o, *args, **kwargs):\n",
    "            try:\n",
    "                o.callback(f'before_{self.nm}')\n",
    "                f(o, *args, **kwargs)\n",
    "                o.callback(f'after_{self.nm}')\n",
    "            except globals()[f'Cancel{self.nm.title()}Exception']: pass\n",
    "            finally: o.callback(f'cleanup_{self.nm}')\n",
    "        return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class with_interceptor:\n",
    "    def __init__(self, name='no name'):\n",
    "        self.name = name\n",
    "        self.stack = []\n",
    "    def __call__(self, f):\n",
    "        def _f(o, *args, **kwargs):\n",
    "            self.stack = [*self.stack, {f.__name__: {'obj': o, 'f': f, 'args': args, 'kwargs': kwargs}}]\n",
    "            f(o, *args, **kwargs)\n",
    "            self.stack = self.stack[:-1]\n",
    "        return _f\n",
    "\n",
    "    def __setattr__(self, k,v) -> None:\n",
    "        print('make pretty intercepting:', (k,v))\n",
    "        super().__setattr__(k,v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "\n",
    "\n",
    "def stored(f):\n",
    "    @wraps(f)\n",
    "    def wrapper(o, *args, **kwds):\n",
    "        store = Writable(o)\n",
    "        u = store.subscribe(lambda x: print(f\"stored_callback: {x}\"))\n",
    "        f(o, *args, **kwds)\n",
    "        u()\n",
    "    return wrapper\n",
    "\n",
    "class Child:\n",
    "\n",
    "    @stored\n",
    "    def do_something(self, x, y, *args, **kwargs):\n",
    "        print('2')\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        z = x + y\n",
    "        def g(t):\n",
    "            z = 3\n",
    "            u = t\n",
    "            def h(z):\n",
    "                a = z\n",
    "            h(u)\n",
    "        g(z)\n",
    "\n",
    "c = Child()\n",
    "c.do_something(1,2,3, a=1, b=2)\n",
    "c.do_something(1,2,3, a=1, b=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def stored(f):\n",
    "    def _f(o, *args, **kwargs):\n",
    "        o.__dict__[f.__name__] = f(o, *args, **kwargs)\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ordinary(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class dummyInterceptor:\n",
    "    def __init__(self, nm): self.nm = nm\n",
    "    def __call__(self, f):\n",
    "        def _f(*args, **kwargs):\n",
    "            f(*args, **kwargs)\n",
    "        return _f\n",
    "\n",
    "    def __setattr__(self, k,v) -> None:\n",
    "        print('intercepting:', (k,v))\n",
    "        super().__setattr__(k,v)\n",
    "\n",
    "# def __call__(self, f):\n",
    "#         def _f(o, *args, **kwargs):\n",
    "#             try:\n",
    "#                 o.callback(f'before_{self.nm}')\n",
    "#                 f(o, *args, **kwargs)\n",
    "#                 o.callback(f'after_{self.nm}')\n",
    "#             except globals()[f'Cancel{self.nm.title()}Exception']: pass\n",
    "#             finally: o.callback(f'cleanup_{self.nm}')\n",
    "#         return _f\n",
    "\n",
    "\n",
    "@dummyInterceptor\n",
    "def dummy(x):\n",
    "    x = 1\n",
    "    def g():\n",
    "        y = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dummy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "f.__code__.co_varnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "f.__code__.co_varnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "learner.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "@fc.patch\n",
    "def __getattr__(self:Learner, name):\n",
    "        if name in ('epochs','epoch','iter','one_batch'): \n",
    "            return partial(self.callback, name)\n",
    "        raise AttributeError(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class with_cbs:\n",
    "    def __init__(self, nm): self.nm = nm\n",
    "    def __call__(self, f):\n",
    "        def _f(o, *args, **kwargs):\n",
    "            try:\n",
    "                o.callback(f'before_{self.nm}')\n",
    "                f(o, *args, **kwargs)\n",
    "                o.callback(f'after_{self.nm}')\n",
    "            except globals()[f'Cancel{self.nm.title()}Exception']: pass\n",
    "            finally: o.callback(f'cleanup_{self.nm}')\n",
    "        return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def callback(self, method_nm): \n",
    "    run_cbs(self.cbs, method_nm, self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|hide\n",
    "\n",
    "# print(state)\n",
    "# class TrainingStore(Writable[TrainingState]):\n",
    "\n",
    "# @fc.patch\n",
    "# def fit(self:Learner, n_epochs, trnState: TrainingState):\n",
    "#     \"Fit the model for `n_epochs` using batches from `dls`\"\n",
    "#     trnState.emit(Event(id=\"before_fit\", payload=None))\n",
    "#     for epoch in range(n_epochs):\n",
    "#         self.one_epoch(is_training=True, trnState=trnState)\n",
    "#         self.one_epoch(is_training=False, trnState=trnState)\n",
    "#         if (trnState.get().should_halt): break\n",
    "\n",
    "# training = TrainingStore(TrainingState(epoch=0, step=0, batch_n=0, batch=None, metrics=None, last_event=None))\n",
    "# u3 = training.subscribe(lambda x: print(f\"3:\\n {x}\"))\n",
    "# @fc.patch\n",
    "# def fit(self:Learner, n_epochs, trnState: TrainingState):\n",
    "#     \"Fit the model for `n_epochs` using batches from `dls`\"\n",
    "#     trnState.emit(Event(id=\"before_fit\", payload=None))\n",
    "#     for epoch in range(n_epochs):\n",
    "#         self.one_epoch(is_training=True, trnState=trnState)\n",
    "#         self.one_epoch(is_training=False, trnState=trnState)\n",
    "#         if (trnState.get().should_halt): break\n",
    "\n",
    "# @fc.patch\n",
    "# def one_epoch(self:Learner, is_training: bool, trnState: TrainingState):\n",
    "#     a = 1\n",
    "#     # print(f\"one_epoch: is_training={is_training}\")\n",
    "#     # print(trnState)\n",
    "#     # trnState._s_is_training = is_training\n",
    "#     # self.dl = self.dls.train if is_training else self.dls.valid\n",
    "#     # trnState.emit(Event(id=f\"before_epoch\", payload=trnState._s_epoch))\n",
    "#     # for batch_n, batch in enumerate(self.dl):\n",
    "#     #     trnState._s_batch_n, trnState._s_batch  = batch_n, batch\n",
    "#     #     # self.one_batch(trnState=trnState)\n",
    "#     #     if (trnState._s_should_halt): break\n",
    "#     # trnState.emit(Event(id=f\"after_epoch\", payload=trnState._s_epoch))\n",
    "\n",
    "\n",
    "\n",
    "# params, state, apply, _ = ms.get()\n",
    "# rng = hk.PRNGSequence(42) # random number generator\n",
    "# @jax.jit\n",
    "# def _predict(params, state, key, batch) -> Tensor:\n",
    "#     logits, new_state = apply(params, state, key, batch.input)\n",
    "#     return jnp.argmax (logits, axis=-1), new_state\n",
    "# key = next(rng)\n",
    "# _predict(params, state, key, batch)\n",
    "# @jax.jit\n",
    "# def _evaluate(params, state, key, batch) -> Tensor:\n",
    "#     preds, _ = _predict(params, state, key, batch)\n",
    "#     return jnp.mean(preds == batch.target)\n",
    "# from torch.utils.benchmark import Timer\n",
    "# evTimer = Timer(stmt=\"_evaluate(params, state, key, batch)\", globals=globals())\n",
    "# evTimer.timeit(1000)\n",
    "# rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "\n",
    "# def evaluate(model: ModelStore, batch: Batch) -> Tensor:\n",
    "#     params, state, apply, _ = model.get()\n",
    "#     key = next(rng)\n",
    "#     return _evaluate(params, state, key, batch)\n",
    "# evaluate(ms, batch)\n",
    "# @jax.jit\n",
    "# def _loss_fn(params, state, key, batch)-> jnp.ndarray:\n",
    "#     targs = batch.target\n",
    "#     preds, new_state = apply(params, state, key, batch.input)\n",
    "#     # return the expectation of the loss wrt the distribution of the targets\n",
    "#     return jnp.sum(optax.softmax_cross_entropy_with_integer_labels(preds, targs)/targs.shape[0]), new_state\n",
    "# key = next(rng)\n",
    "# loss, new_state = _loss_fn(params, state, key, batch)\n",
    "# lfTimer = Timer(stmt=\"_loss_fn(params, state, key, batch)\", globals=globals())\n",
    "# lfTimer.timeit(1000)\n",
    "\n",
    "# a = NamedTuple('A', [('a', int), ('b', int)])(1,2)\n",
    "# b = NamedTuple('A', [('a', int), ('b', int)])(3,3)\n",
    "# s1 = set(a._asdict().items())\n",
    "# s2 = set(b._asdict().items())\n",
    "# s1 ^ s2\n",
    "# trnState = TrainingStore(TrainingState(epoch=0, step=0, batch_n=0, batch=None, metrics=None, last_event=None))\n",
    "# logs = []\n",
    "# def logger(x):\n",
    "#     logs.append(x)\n",
    "#     last = set((logs[-1])._asdict().items())\n",
    "#     curr = set((x)._asdict().items())\n",
    "#     print (last ^ curr)\n",
    "\n",
    "# u4 = trnState.subscribe(lambda x: logger(x))\n",
    "# def one_batch(self):\n",
    "#     self.preds = self.model(self.batch[0])\n",
    "#     self.loss = self.loss_func(self.preds, self.batch[1])\n",
    "#     if self.model.training:\n",
    "#         self.loss.backward()\n",
    "#         self.opt.step()\n",
    "#         self.opt.zero_grad()\n",
    "# class Learner():\n",
    "#     def __init__(self, model, dls, loss_func, lr, cbs, opt_func=optim.SGD): fc.store_attr()\n",
    "\n",
    "#     def one_batch(self):\n",
    "#         self.preds = self.model(self.batch[0])\n",
    "#         self.loss = self.loss_func(self.preds, self.batch[1])\n",
    "#         if self.model.training:\n",
    "#             self.loss.backward()\n",
    "#             self.opt.step()\n",
    "#             self.opt.zero_grad()\n",
    "\n",
    "#     def one_epoch(self, train):\n",
    "#         self.model.train(train)\n",
    "#         self.dl = self.dls.train if train else self.dls.valid\n",
    "#         try:\n",
    "#             self.callback('before_epoch')\n",
    "#             for self.iter,self.batch in enumerate(self.dl):\n",
    "#                 try:\n",
    "#                     self.callback('before_batch')\n",
    "#                     self.one_batch()\n",
    "#                     self.callback('after_batch')\n",
    "#                 except CancelBatchException: pass\n",
    "#             self.callback('after_epoch')\n",
    "#         except CancelEpochException: pass\n",
    "    \n",
    "#     def fit(self, n_epochs):\n",
    "#         self.n_epochs = n_epochs\n",
    "#         self.epochs = range(n_epochs)\n",
    "#         self.opt = self.opt_func(self.model.parameters(), self.lr)\n",
    "#         try:\n",
    "#             self.callback('before_fit')\n",
    "#             for self.epoch in self.epochs:\n",
    "#                 self.one_epoch(True)\n",
    "#                 self.one_epoch(False)\n",
    "#             self.callback('after_fit')\n",
    "#         except CancelFitException: pass\n",
    "\n",
    "#     def callback(self, method_nm): run_cbs(self.cbs, method_nm, self)\n",
    "# #|export\n",
    "# class with_cbs:\n",
    "#     def __init__(self, nm): self.nm = nm\n",
    "#     def __call__(self, f):\n",
    "#         def _f(o, *args, **kwargs):\n",
    "#             try:\n",
    "#                 o.callback(f'before_{self.nm}')\n",
    "#                 f(o, *args, **kwargs)\n",
    "#                 o.callback(f'after_{self.nm}')\n",
    "#             except globals()[f'Cancel{self.nm.title()}Exception']: pass\n",
    "#             finally: o.callback(f'cleanup_{self.nm}')\n",
    "#         return _f\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "# params, state, apply, _ = ms.get()\n",
    "# @jax.jit\n",
    "# def _loss_fn(params, state, batch)-> Tuple[jnp.ndarray, PyTree]:\n",
    "#     bs, *_ = batch.target.shape\n",
    "#     logits, state = apply(params, state, next(rng), batch.input)\n",
    "#     state = {'a':1, 'b':2}\n",
    "#     return jnp.sum(optax.softmax_cross_entropy_with_integer_labels(logits, batch.target)/bs)\n",
    "\n",
    "# def loss_fn(model: ModelStore, batch: Batch) -> float:\n",
    "#     params, state, apply, _ = model.get()\n",
    "#     loss_value =  _loss_fn(params, state, batch)\n",
    "#     new_model = Model(**(m._asdict()|{'state': new_state}))\n",
    "#     model.set(new_model)\n",
    "#     return float(loss_value)\n",
    "\n",
    "# loss_fn(ms, batch)\n",
    "# ms\n",
    "# from functools import partial\n",
    "# rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "\n",
    "# def update(model: ModelStore, optimizer: OptimizerStore, batch: Batch)->None:\n",
    "#     m = model.get()\n",
    "#     o = optimizer.get()\n",
    "#     f = partial(loss_fn)(model=model)\n",
    "#     grads = jax.grad(loss_fn)(batch)\n",
    "#     @jax.jit\n",
    "#     def _update():\n",
    "#         updates, new_optState = o.apply(grads, o.state)\n",
    "#         new_model_params = optax.apply_updates(m.params, updates)\n",
    "#         return new_model_params, new_optState\n",
    "#     new_model_params, new_optState = _update()\n",
    "#     new_model = Model(**(m._asdict()|{'params': new_model_params}))\n",
    "#     new_optimizer = Optimizer(**(o._asdict()|{'state': new_optState}))\n",
    "#     model.set(new_model)\n",
    "#     optimizer.set(new_optimizer)\n",
    "#     return None\n",
    "# todo: tentar jax.tree_util.Partial\n",
    "# m = ms.get()\n",
    "# o = os.get()\n",
    "# f = partial(loss_fn, model=ms)\n",
    "# grads = jax.grad(f)(batch)\n",
    "# rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "# params, state, apply, _ = ms.get()\n",
    "# def loss_fn():\n",
    "#     loss_value, new_state =  _loss_fn(params, state, batch)\n",
    "    \n",
    "# grads = jax.grad(_loss_fn)(params, state, batch)\n",
    "# grads\n",
    "# update(ms, os, batch)\n",
    "\n",
    "# rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "\n",
    "# def loss_fn(model: ModelStore, batch: Batch) -> float:\n",
    "#     params, state, apply, _ = model.get()\n",
    "#     @jax.jit\n",
    "#     def _loss(params, state, batch)-> jnp.ndarray:\n",
    "#         bs, *_ = batch.target.shape\n",
    "#         logits, state = (apply)(params, state, next(rng), batch.input)\n",
    "#         return jnp.sum(optax.softmax_cross_entropy_with_integer_labels(logits, batch.target)/bs), state\n",
    "#     loss_value, new_state =  _loss(params, state, batch)\n",
    "#     new_model = Model(**(m._asdict()|{'state': new_state}))\n",
    "#     model.set(new_model)\n",
    "#     return float(loss_value)\n",
    "\n",
    "# loss_fn(ms, batch)\n",
    "# def get_loss(loss_func, *args): return jax.jit(lambda params: loss_func(get_model(params), *args))\n",
    "# mse_loss = get_loss(mse, xb,tb) \n",
    "# mse_loss, mse_loss(W)\n",
    "# from torch.utils.benchmark import Timer\n",
    "# jax_grad = Timer( stmt=\"jax.grad(mse_loss)\", globals=globals())\n",
    "# jax_grad.timeit(1000)\n",
    "# class TrainingStore(Writable[TrainingState]):\n",
    "\n",
    "#     def emit(self, event: Event):\n",
    "#         self.set(self.value._replace(last_event=event))\n",
    "#     # def __getattr__(self, name): # there  is a bug, I can't fi\n",
    "#     #     if name[:3]=='_s_' : return getattr(self.value, name[3:])\n",
    "#     #     else: return super().__getattr__(name)\n",
    "#     # def __setattr__(self, name, value):\n",
    "#     #     if name[:3]=='_s_' and hasattr(self.value, name[3:]):\n",
    "#     #         self.set(self.value._replace(**{name[3:]: value}))\n",
    "#     #     else: super().__setattr__(name, value)\n",
    "#     def __repr__(self) -> str:\n",
    "#         return f\"{self.__class__.__name__}:\\n{self}\"\n",
    "#     def __str__(self) -> str:\n",
    "#         state = list(self.value._asdict().items())\n",
    "#         cbs = [(f\"{i}:\", v) for i, v in enumerate(self.subscribers)]\n",
    "#         table = list(itertools.zip_longest(list(zip(*state)),list(zip(*cbs))))\n",
    "#         return tabulate(table, headers=['State', 'Calbacks'], tablefmt='grid')\n",
    "# def __repr__(self) -> str:\n",
    "#         return f\"{self.__class__.__name__}:\\n{self}\"\n",
    "#     def __str__(self) -> str:\n",
    "#         state = list(self.value._asdict().items())\n",
    "#         state_t = list(zip(*state))\n",
    "#         cbs = [(f\"{i}:\", v) for i, v in enumerate(self.subscribers)]\n",
    "#         cbs_t = list(zip(*cbs))\n",
    "#         table = list(itertools.zip_longest(*state_t,*cbs_t))\n",
    "#         return tabulate(table, headers=['','State','', 'Calbacks'], tablefmt='grid')\n",
    "#     # @property\n",
    "#     # def _(self):\n",
    "#     #     \"\"\"The store value.\"\"\"\n",
    "#     #     return self.value\n",
    "#     # @_.setter\n",
    "#     # def _(self, value: TrainingState):\n",
    "#     #     self.set(value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
