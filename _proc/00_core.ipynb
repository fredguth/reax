{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: This is the core of the `Reax` lib.\n",
    "output-file: core.html\n",
    "title: core\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in `miniai`, we wil be using the `FashionMnist` Dataset for demonstration.   `Reax` is not intended to be a complete library, the `data` module is just a copy from [miniai]() to make it work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from reax.data import DataLoaders, Batch, Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 20:50:50.805520: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:429] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-03-01 20:50:50.814382: E external/org_tensorflow/tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (external/org_tensorflow/tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:627) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t_PyObject_MakeTpCall\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyFunction_Vectorcall\n",
      "\tPyObject_Call\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyFunction_Vectorcall\n",
      "\tPyObject_Call\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t\n",
      "\tPyObject_Call\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyFunction_Vectorcall\n",
      "\tPyObject_Call\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyFunction_Vectorcall\n",
      "\tPyObject_Call\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyFunction_Vectorcall\n",
      "\t\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t_PyObject_MakeTpCall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\tPyObject_Repr\n",
      "\tPyUnicode_Format\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyObject_FastCallDictTstate\n",
      "\t_PyObject_Call_Prepend\n",
      "\t\n",
      "\t_PyObject_MakeTpCall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyFunction_Vectorcall\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyObject_FastCallDictTstate\n",
      "\t_PyObject_Call_Prepend\n",
      "\t\n",
      "\t_PyObject_MakeTpCall\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalCodeWithName\n",
      "\tPyEval_EvalCodeEx\n",
      "\tPyEval_EvalCode\n",
      "\t\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t_PyEval_EvalFrameDefault\n",
      "\t\n",
      "\t\n",
      "*** End stack trace ***\n",
      "\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "INTERNAL: RET_CHECK failure (external/org_tensorflow/tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:627) dnn != nullptr ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.miniconda3/envs/jaxai3/lib/python3.9/site-packages/IPython/core/formatters.py:706\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    699\u001b[0m stream \u001b[39m=\u001b[39m StringIO()\n\u001b[1;32m    700\u001b[0m printer \u001b[39m=\u001b[39m pretty\u001b[39m.\u001b[39mRepresentationPrinter(stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    701\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnewline,\n\u001b[1;32m    702\u001b[0m     max_seq_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_seq_length,\n\u001b[1;32m    703\u001b[0m     singleton_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msingleton_printers,\n\u001b[1;32m    704\u001b[0m     type_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype_printers,\n\u001b[1;32m    705\u001b[0m     deferred_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeferred_printers)\n\u001b[0;32m--> 706\u001b[0m printer\u001b[39m.\u001b[39;49mpretty(obj)\n\u001b[1;32m    707\u001b[0m printer\u001b[39m.\u001b[39mflush()\n\u001b[1;32m    708\u001b[0m \u001b[39mreturn\u001b[39;00m stream\u001b[39m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/.miniconda3/envs/jaxai3/lib/python3.9/site-packages/IPython/lib/pretty.py:410\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    407\u001b[0m                         \u001b[39mreturn\u001b[39;00m meth(obj, \u001b[39mself\u001b[39m, cycle)\n\u001b[1;32m    408\u001b[0m                 \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mobject\u001b[39m \\\n\u001b[1;32m    409\u001b[0m                         \u001b[39mand\u001b[39;00m callable(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39m__repr__\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[0;32m--> 410\u001b[0m                     \u001b[39mreturn\u001b[39;00m _repr_pprint(obj, \u001b[39mself\u001b[39;49m, cycle)\n\u001b[1;32m    412\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_pprint(obj, \u001b[39mself\u001b[39m, cycle)\n\u001b[1;32m    413\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.miniconda3/envs/jaxai3/lib/python3.9/site-packages/IPython/lib/pretty.py:778\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[39m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mrepr\u001b[39;49m(obj)\n\u001b[1;32m    779\u001b[0m lines \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39msplitlines()\n\u001b[1;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m p\u001b[39m.\u001b[39mgroup():\n",
      "File \u001b[0;32m~/.miniconda3/envs/jaxai3/lib/python3.9/collections/__init__.py:458\u001b[0m, in \u001b[0;36mnamedtuple.<locals>.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__repr__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    457\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mReturn a nicely formatted representation string\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m+\u001b[39m repr_fmt \u001b[39m%\u001b[39;49m \u001b[39mself\u001b[39;49m\n",
      "File \u001b[0;32m~/code/lovely-jax/lovely_jax/patch.py:30\u001b[0m, in \u001b[0;36m_monkey_patch.<locals>.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39m@patch_to\u001b[39m(\u001b[39mcls\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__repr__\u001b[39m(\u001b[39mself\u001b[39m: jax\u001b[39m.\u001b[39mArray):\n\u001b[0;32m---> 30\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mstr\u001b[39;49m(StrProxy(\u001b[39mself\u001b[39;49m))\n",
      "File \u001b[0;32m~/code/lovely-jax/lovely_jax/repr_str.py:181\u001b[0m, in \u001b[0;36mStrProxy.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__repr__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 181\u001b[0m     \u001b[39mreturn\u001b[39;00m to_str(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx, plain\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplain, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    182\u001b[0m                   depth\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdepth, lvl\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlvl, color\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolor)\n",
      "File \u001b[0;32m~/code/lovely-jax/lovely_jax/repr_str.py:136\u001b[0m, in \u001b[0;36mto_str\u001b[0;34m(x, plain, verbose, depth, lvl, color)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39m# `lovely-numpy` is used to calculate stats when doing so on GPU would require\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39m# memory allocation (not float tensors, tensors with bad numbers), or if the\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m# data is on CPU (because numpy is faster).\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m# Temporarily set the numpy config to match our config for consistency.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m lnp_config(precision\u001b[39m=\u001b[39mconf\u001b[39m.\u001b[39mprecision,\n\u001b[1;32m    132\u001b[0m                 threshold_min\u001b[39m=\u001b[39mconf\u001b[39m.\u001b[39mthreshold_min,\n\u001b[1;32m    133\u001b[0m                 threshold_max\u001b[39m=\u001b[39mconf\u001b[39m.\u001b[39mthreshold_max,\n\u001b[1;32m    134\u001b[0m                 sci_mode\u001b[39m=\u001b[39mconf\u001b[39m.\u001b[39msci_mode):\n\u001b[0;32m--> 136\u001b[0m     \u001b[39mif\u001b[39;00m is_cpu(x) \u001b[39mor\u001b[39;00m is_nasty(x):\n\u001b[1;32m    137\u001b[0m         common \u001b[39m=\u001b[39m np_to_str_common(np\u001b[39m.\u001b[39marray(x), color\u001b[39m=\u001b[39mcolor)\n\u001b[1;32m    138\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/code/lovely-jax/lovely_jax/repr_str.py:54\u001b[0m, in \u001b[0;36mis_nasty\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return true of any `x` values are inf or nan\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39m# min/max don't like zero-lenght arrays\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m x_min \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mmin()\n\u001b[1;32m     55\u001b[0m x_max \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mmax()\n\u001b[1;32m     57\u001b[0m \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39misnan(x_min) \u001b[39mor\u001b[39;00m jnp\u001b[39m.\u001b[39misinf(x_min) \u001b[39mor\u001b[39;00m jnp\u001b[39m.\u001b[39misinf(x_max)\n",
      "File \u001b[0;32m~/.miniconda3/envs/jaxai3/lib/python3.9/site-packages/jax/_src/numpy/reductions.py:274\u001b[0m, in \u001b[0;36mmin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[39m@_wraps\u001b[39m(np\u001b[39m.\u001b[39mmin, skip_params\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mout\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    271\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmin\u001b[39m(a: ArrayLike, axis: Axis \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, out: \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    272\u001b[0m         keepdims: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, initial: Optional[ArrayLike] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    273\u001b[0m         where: Optional[ArrayLike] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Array:\n\u001b[0;32m--> 274\u001b[0m   \u001b[39mreturn\u001b[39;00m _reduce_min(a, axis\u001b[39m=\u001b[39;49m_ensure_optional_axes(axis), out\u001b[39m=\u001b[39;49mout,\n\u001b[1;32m    275\u001b[0m                      keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.miniconda3/envs/jaxai3/lib/python3.9/site-packages/jax/_src/dispatch.py:1040\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, built_c, options, host_callbacks)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39mcompile(built_c, compile_options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m   1036\u001b[0m                          host_callbacks\u001b[39m=\u001b[39mhost_callbacks)\n\u001b[1;32m   1037\u001b[0m \u001b[39m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[39m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mcompile(built_c, compile_options\u001b[39m=\u001b[39;49moptions)\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: INTERNAL: RET_CHECK failure (external/org_tensorflow/tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:627) dnn != nullptr "
     ]
    }
   ],
   "source": [
    "XMEAN,XSTD, BATCH_SIZE, NUM_CLASSES = 0.28,0.35, 500, 10\n",
    "\n",
    "tfm = transforms.Compose([transforms.PILToTensor(), \n",
    "                          transforms.Lambda(lambda x: x/255), transforms.Normalize(XMEAN, XSTD), \n",
    "                          transforms.Lambda(lambda x: torch.flatten(x))])\n",
    "ds = partial(torchvision.datasets.FashionMNIST,root=\"data\",download=True, transform = tfm)\n",
    "train_ds, valid_ds = ds(train=True), ds(train=False)\n",
    "tdl = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "vdl = DataLoader(valid_ds, batch_size=BATCH_SIZE)\n",
    "dls = DataLoaders(tdl, vdl)\n",
    "batch = Batch(*map(jnp.array, next(iter(dls.train))))\n",
    "batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "Have you noticed the `lj.monkey_patch()` call? This is a call for `lovely-jax`, the wonderful library that makes the JAX array representation more friendly.\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic [Haiku](https://dm-haiku.readthedocs.io/) object to represent a model is a [TransformedWithState](https://dm-haiku.readthedocs.io/en/latest/api.html#transformedwithstate).  It represents a `function` or `module` that has been transformed by a `hk.transform` function.  Here we are using `hk.transform_with_state` which is the superset of the transform functions.  \n",
    "\n",
    "State in the `Haiku` lingo means everything that make your original `Callable` not a pure function.  It is the context or state.  Somoe common `DNN` modules like `batch_norm`can keep some `state` to perform its work.  `State`, `Buffers` and `Context` are common names for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def forward(x:jnp.array) ->jnp.ndarray:\n",
    "  return hk.nets.MLP(output_sizes=[50,NUM_CLASSES])(x) # todo: remove NUM_CLASSES dependency\n",
    "network = hk.transform_with_state(forward)\n",
    "type(network)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `Reax`, a [`Model`](https://fredguth.github.io/reax/core.html#model) is an immutable object. [PyTrees](https://jax.readthedocs.io/en/latest/pytrees.html) are JAX datastructures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Model(NamedTuple):\n",
    "    params: PyTree # the models parameters, weights and biases\n",
    "    state: PyTree  # the model auxiliary state, e.g. batchnorm buffers\n",
    "    apply: ApplyFn # the model forward pass function\n",
    "    input_shape: Tuple[int, ...] # the shape of the input, used to infer the model output shape\n",
    "\n",
    "    rng = hk.PRNGSequence(42) # random number generator\n",
    "\n",
    "    @staticmethod\n",
    "    def from_haiku(\n",
    "        transformed: hk.TransformedWithState,       # transformed haiku model\n",
    "        x: Tensor                                   # example input (e.g. batch.input)\n",
    "    ):\n",
    "        ''' Create a Model from a Haiku Transformed object and an example input.'''\n",
    "        init, apply = transformed\n",
    "        params, state = jax.jit(init)(next(Model.rng), x)\n",
    "        return Model(params=params, state=state, apply=apply, input_shape=x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L28){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Model\n",
       "\n",
       ">      Model (params:Union[jax.Array,numpy.ndarray,Tuple[ForwardRef('PyTree'),..\n",
       ">             .],List[ForwardRef('PyTree')],Dict[Hashable,ForwardRef('PyTree')],\n",
       ">             Mapping[str,Mapping[str,jax.Array]],Iterable[ForwardRef('ArrayTree\n",
       ">             ')],Mapping[Any,ForwardRef('ArrayTree')],NoneType], state:Union[ja\n",
       ">             x.Array,numpy.ndarray,Tuple[ForwardRef('PyTree'),...],List[Forward\n",
       ">             Ref('PyTree')],Dict[Hashable,ForwardRef('PyTree')],Mapping[str,Map\n",
       ">             ping[str,jax.Array]],Iterable[ForwardRef('ArrayTree')],Mapping[Any\n",
       ">             ,ForwardRef('ArrayTree')],NoneType], apply:Callable[...,Tuple[Unio\n",
       ">             n[jax.Array,numpy.ndarray],Union[jax.Array,numpy.ndarray,Tuple[For\n",
       ">             wardRef('PyTree'),...],List[ForwardRef('PyTree')],Dict[Hashable,Fo\n",
       ">             rwardRef('PyTree')],Mapping[str,Mapping[str,jax.Array]],Iterable[F\n",
       ">             orwardRef('ArrayTree')],Mapping[Any,ForwardRef('ArrayTree')],NoneT\n",
       ">             ype]]], input_shape:Tuple[int,...])"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L28){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Model\n",
       "\n",
       ">      Model (params:Union[jax.Array,numpy.ndarray,Tuple[ForwardRef('PyTree'),..\n",
       ">             .],List[ForwardRef('PyTree')],Dict[Hashable,ForwardRef('PyTree')],\n",
       ">             Mapping[str,Mapping[str,jax.Array]],Iterable[ForwardRef('ArrayTree\n",
       ">             ')],Mapping[Any,ForwardRef('ArrayTree')],NoneType], state:Union[ja\n",
       ">             x.Array,numpy.ndarray,Tuple[ForwardRef('PyTree'),...],List[Forward\n",
       ">             Ref('PyTree')],Dict[Hashable,ForwardRef('PyTree')],Mapping[str,Map\n",
       ">             ping[str,jax.Array]],Iterable[ForwardRef('ArrayTree')],Mapping[Any\n",
       ">             ,ForwardRef('ArrayTree')],NoneType], apply:Callable[...,Tuple[Unio\n",
       ">             n[jax.Array,numpy.ndarray],Union[jax.Array,numpy.ndarray,Tuple[For\n",
       ">             wardRef('PyTree'),...],List[ForwardRef('PyTree')],Dict[Hashable,Fo\n",
       ">             rwardRef('PyTree')],Mapping[str,Mapping[str,jax.Array]],Iterable[F\n",
       ">             orwardRef('ArrayTree')],Mapping[Any,ForwardRef('ArrayTree')],NoneT\n",
       ">             ype]]], input_shape:Tuple[int,...])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "m = Model.from_haiku(transformed=network, x=batch.input)\n",
    "m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep us sane and improve the model representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "m = Model.from_haiku(transformed=network, x=batch.input)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Reactivity (Model Store)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we will start to play with reactivity.  In `fastai` (also in Keras, vanilla PyTorch, etc) there is the concept of `Callbacks`.  It is the way to be notified when something of interest happens. \n",
    "\n",
    "> Don't nudge me, let me __call you back__ when I have something for you!\n",
    "\n",
    "In general, you will need a callback only during training, after all, it is when your `things` change.  The model, the hyperparameters, the metrics, etc.\n",
    "\n",
    "The __fastai/miniai__ [`Learner`](https://fredguth.github.io/reax/core.html#learner) is an `Observable` and you can hold multiple callbacks. Every callback keep its state in the Learner object. You can have callbacks for metrics, for logging and saving the training process... callbacks that depend on other callbacks! That is why there is that ... shall I say... __ugly__ `order` property in the `Callback`class.\n",
    "\n",
    "`Reax` is just an experiment on how to handle this reactivity in another way.  Maybe it will prove itself too bloated... or not. I decided to do it in `JAX/Haiku` to force a `functional programming` perspective.\n",
    "\n",
    "The basic abstraction in  `Reax` are `stores`, observables that hold any value. We could have used [RxPy] which is an incredible package. But its superpowers may be too much for what we need. That is why I took inspiration from the `Svelte` JS framework to create `stores` (it became its own package, [Sveltish](https://fredguth.github.io/sveltish))."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [`ModelStore`](https://fredguth.github.io/reax/core.html#modelstore) is just a [`Writable`](https://fredguth.github.io/reax/stores.html#writable) store that holds values of type [`Model`](https://fredguth.github.io/reax/core.html#model). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L71){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelStore\n",
       "\n",
       ">      ModelStore (initial_value:__main__.Model)\n",
       "\n",
       "A Model store. Custom Writable store\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| initial_value | Model | Initial value of the store |\n",
       "| **Returns** | **None** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L71){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelStore\n",
       "\n",
       ">      ModelStore (initial_value:__main__.Model)\n",
       "\n",
       "A Model store. Custom Writable store\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| initial_value | Model | Initial value of the store |\n",
       "| **Returns** | **None** |  |"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ModelStore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving the ModelStore representation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also may improve its representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ms = ModelStore(m)\n",
    "ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(ms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `callback` is any `Callable` that you pass on `subscribe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "u1 = ms.subscribe(lambda x: print(\"1: callback 1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A change in the store value, triggers all callbacks subscribed to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "m = ms.get()\n",
    "ms.set(Model(**(m._asdict()|{\"state\": {'a': 1, 'b': 2}})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can have different `stores` for different things.  For example, this is a simpler one to deal with the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L103){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Optimizer\n",
       "\n",
       ">      Optimizer (state:Union[jax.Array,Iterable[ForwardRef('ArrayTree')],Mappin\n",
       ">                 g[Any,ForwardRef('ArrayTree')]], apply:Callable)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L103){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Optimizer\n",
       "\n",
       ">      Optimizer (state:Union[jax.Array,Iterable[ForwardRef('ArrayTree')],Mappin\n",
       ">                 g[Any,ForwardRef('ArrayTree')]], apply:Callable)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(Optimizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, we will use [Optax](https://optax.readthedocs.io/), which is a good companion for `Haiku`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "grad_tfm = optax.sgd(1e-3)\n",
    "apply = grad_tfm.update\n",
    "optState = grad_tfm.init(m.params) # you initialize the optimizer with the model params\n",
    "optimizer = Optimizer(state=optState, apply=apply)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "os= OptimizerStore(optimizer)\n",
    "u2 = os.subscribe(lambda x: print(f\"callback 2: {x}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "grad_tf2 = optax.adam(1e-4)\n",
    "optState2 = grad_tf2.init(m.params)\n",
    "os.set(Optimizer(state=optState2, apply=grad_tf2.update))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up... you should remember to unsubscribe when you are done with a store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "u1(), u2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "m = Model.from_haiku(transformed=network, x=batch.input)\n",
    "ms = ModelStore(m)\n",
    "u1 = ms.subscribe(lambda x: print(f\"cb 1:\\n{x}\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we arrived at the Training, the  `core` of the `core`  ```¯\\_(ツ)_/¯```\n",
    "\n",
    "Here is where we will most need callbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in `fastai`, we create a [`Learner`](https://fredguth.github.io/reax/core.html#learner) class that will deal with the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L111){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Learner\n",
       "\n",
       ">      Learner (model:__main__.ModelStore, dls:reax.data.DataLoaders, loss_func:\n",
       ">               Callable[[Union[jax.Array,numpy.ndarray],Union[jax.Array,numpy.n\n",
       ">               darray]],Union[jax.Array,numpy.ndarray]],\n",
       ">               optimizer:reax.stores.Writable[__main__.Optimizer])\n",
       "\n",
       "Basic class for handling the training loop."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L111){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Learner\n",
       "\n",
       ">      Learner (model:__main__.ModelStore, dls:reax.data.DataLoaders, loss_func:\n",
       ">               Callable[[Union[jax.Array,numpy.ndarray],Union[jax.Array,numpy.n\n",
       ">               darray]],Union[jax.Array,numpy.ndarray]],\n",
       ">               optimizer:reax.stores.Writable[__main__.Optimizer])\n",
       "\n",
       "Basic class for handling the training loop."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(Learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "learner = Learner(model=ms, dls=dls, loss_func=optax.softmax_cross_entropy_with_integer_labels, optimizer=os)\n",
    "learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learner itself, is not a store, but holds different stores for different aspects of the training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a [`ModelStore`](https://fredguth.github.io/reax/core.html#modelstore), an `OptimizerStore`... it is only missing the most important thing we want to __observe__... the training loop itself. We need a [`TrainingStore`](https://fredguth.github.io/reax/core.html#trainingstore).\n",
    "\n",
    "But for that... let's first examine what we need.  Let's take a look in the __training loop__:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Fit`: the training Loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# pseudo-code\n",
    "\n",
    "def fit(epochs: int)->None:\n",
    "    '''Train the model for a number of epochs.'''\n",
    "    # before fit\n",
    "    for epoch in range(epochs):\n",
    "        # is_training\n",
    "        one_epoch(dls.train) # train for one epoch\n",
    "        # is_validating\n",
    "        one_epoch(dls.valid) # validate for one epoch\n",
    "        # should halt epochs?\n",
    "    # after fit\n",
    "\n",
    "def one_epoch(dl)->None:\n",
    "    '''Train or validate for one epoch.'''\n",
    "    # before epoch\n",
    "    for batch_n, batch in enumerate(dl): \n",
    "        one_batch(batch_n, batch)\n",
    "        # should halt batches?\n",
    "    # after epoch\n",
    "\n",
    "def one_batch(batch_n: int, batch: Batch)->None:\n",
    "    '''Train or validate for one batch.'''\n",
    "    # before batch\n",
    "    predict(...) # preds\n",
    "    evaluate(...)# loss\n",
    "    update model(...) if is_training\n",
    "    # after batch\n",
    "````"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our [`TrainingStore`](https://fredguth.github.io/reax/core.html#trainingstore) shall tell us where we are in the training loop and some information relevant at this point.\n",
    "\n",
    ">  I am `training`, `epoch` 5, `iteration` 345, after `evaluate` with certain `current loss`.\n",
    "\n",
    "\n",
    "Another aspect is that it seems it should be a [`Readable`](https://fredguth.github.io/reax/stores.html#readable) store, afterall, we don't want any callback being able to change information like:\n",
    "`in which batch of which epoch am I?`\n",
    "\n",
    "Exceptionally, we want to tell the [`TrainingStore`](https://fredguth.github.io/reax/core.html#trainingstore) to halt.\n",
    "\n",
    "Let's start with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L123){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TrainingState\n",
       "\n",
       ">      TrainingState (epochs:int, epoch:int, step:int, iter:int,\n",
       ">                     batch:Optional[reax.data.Batch], last:Dict=None,\n",
       ">                     is_running:bool=False, is_training:bool=False,\n",
       ">                     is_validating:bool=False, should_halt:bool=False)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L123){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TrainingState\n",
       "\n",
       ">      TrainingState (epochs:int, epoch:int, step:int, iter:int,\n",
       ">                     batch:Optional[reax.data.Batch], last:Dict=None,\n",
       ">                     is_running:bool=False, is_training:bool=False,\n",
       ">                     is_validating:bool=False, should_halt:bool=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(TrainingState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "t = TrainingState(epochs=0, epoch=0, step=0, iter=0, batch=None)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L148){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TrainingStore\n",
       "\n",
       ">      TrainingStore (initial_value:T, start:Notifier)\n",
       "\n",
       "A store that keeps tracking of the training loop state\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| initial_value | T | initial value of the store |\n",
       "| start | Notifier | function called when the first subscriber is added |\n",
       "| **Returns** | **None** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L148){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TrainingStore\n",
       "\n",
       ">      TrainingStore (initial_value:T, start:Notifier)\n",
       "\n",
       "A store that keeps tracking of the training loop state\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| initial_value | T | initial value of the store |\n",
       "| start | Notifier | function called when the first subscriber is added |\n",
       "| **Returns** | **None** |  |"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(TrainingStore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TrainingStore representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# a = [(\"A\", \"B\", \"C\"), (1,2,3)]\n",
    "# b = [(\"D\", \"E\", None), (4,5,None)]\n",
    "a = [(\"A\", 1), [\"B\", 2], [\"C\", 3]]\n",
    "b = [[\"D\", 4], [\"E\", 5]]\n",
    "c = list(zip(*a))\n",
    "d = list(zip(*b))\n",
    "table = list(itertools.zip_longest(*c,*d))\n",
    "print(tabulate(table, headers=['','H1','', \"H2\"], tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "a = [[\"A\", 1], [\"B\", 2], [\"C\", 3]]\n",
    "b = []\n",
    "c = list(zip(*a))\n",
    "d = list(zip(*b))\n",
    "table = list(itertools.zip_longest(*c,*d))\n",
    "print(tabulate(table, headers=['','H1','', \"H2\"], tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "a = [('epoch', 0), ('step', 0), ('batch_n', 0), ('batch', None), ('metrics', None), ('last_event', None), ('is_training', False), ('should_halt', False)]\n",
    "b = [('0:', lambda:None)]\n",
    "c = list(zip(*a))\n",
    "d = list(zip(*b))\n",
    "table = list(itertools.zip_longest(*c,*d))\n",
    "print(tabulate(table, headers=['','H1','', \"H2\"], tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ts = TrainingStore(t, lambda x:None)\n",
    "u4 = ts.subscribe(lambda x: print(f\"callback 4:\\n {x}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "unsubs = []\n",
    "for i in range(12):\n",
    "    u = ts.subscribe(lambda x: print(f\"callback: {i}\"))\n",
    "    unsubs.append(u)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for u in unsubs: u()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# class TrainingStore(Writable[TrainingState]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# @fc.patch\n",
    "# def fit(self:Learner, n_epochs, trnState: TrainingState):\n",
    "#     \"Fit the model for `n_epochs` using batches from `dls`\"\n",
    "#     trnState.emit(Event(id=\"before_fit\", payload=None))\n",
    "#     for epoch in range(n_epochs):\n",
    "#         self.one_epoch(is_training=True, trnState=trnState)\n",
    "#         self.one_epoch(is_training=False, trnState=trnState)\n",
    "#         if (trnState.get().should_halt): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# training = TrainingStore(TrainingState(epoch=0, step=0, batch_n=0, batch=None, metrics=None, last_event=None))\n",
    "# u3 = training.subscribe(lambda x: print(f\"3:\\n {x}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# @fc.patch\n",
    "# def fit(self:Learner, n_epochs, trnState: TrainingState):\n",
    "#     \"Fit the model for `n_epochs` using batches from `dls`\"\n",
    "#     trnState.emit(Event(id=\"before_fit\", payload=None))\n",
    "#     for epoch in range(n_epochs):\n",
    "#         self.one_epoch(is_training=True, trnState=trnState)\n",
    "#         self.one_epoch(is_training=False, trnState=trnState)\n",
    "#         if (trnState.get().should_halt): break\n",
    "\n",
    "# @fc.patch\n",
    "# def one_epoch(self:Learner, is_training: bool, trnState: TrainingState):\n",
    "#     a = 1\n",
    "#     # print(f\"one_epoch: is_training={is_training}\")\n",
    "#     # print(trnState)\n",
    "#     # trnState._s_is_training = is_training\n",
    "#     # self.dl = self.dls.train if is_training else self.dls.valid\n",
    "#     # trnState.emit(Event(id=f\"before_epoch\", payload=trnState._s_epoch))\n",
    "#     # for batch_n, batch in enumerate(self.dl):\n",
    "#     #     trnState._s_batch_n, trnState._s_batch  = batch_n, batch\n",
    "#     #     # self.one_batch(trnState=trnState)\n",
    "#     #     if (trnState._s_should_halt): break\n",
    "#     # trnState.emit(Event(id=f\"after_epoch\", payload=trnState._s_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# params, state, apply, _ = ms.get()\n",
    "# rng = hk.PRNGSequence(42) # random number generator\n",
    "# @jax.jit\n",
    "# def _predict(params, state, key, batch) -> Tensor:\n",
    "#     logits, new_state = apply(params, state, key, batch.input)\n",
    "#     return jnp.argmax (logits, axis=-1), new_state\n",
    "# key = next(rng)\n",
    "# _predict(params, state, key, batch)\n",
    "# @jax.jit\n",
    "# def _evaluate(params, state, key, batch) -> Tensor:\n",
    "#     preds, _ = _predict(params, state, key, batch)\n",
    "#     return jnp.mean(preds == batch.target)\n",
    "# from torch.utils.benchmark import Timer\n",
    "# evTimer = Timer(stmt=\"_evaluate(params, state, key, batch)\", globals=globals())\n",
    "# evTimer.timeit(1000)\n",
    "# rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "\n",
    "# def evaluate(model: ModelStore, batch: Batch) -> Tensor:\n",
    "#     params, state, apply, _ = model.get()\n",
    "#     key = next(rng)\n",
    "#     return _evaluate(params, state, key, batch)\n",
    "# evaluate(ms, batch)\n",
    "# @jax.jit\n",
    "# def _loss_fn(params, state, key, batch)-> jnp.ndarray:\n",
    "#     targs = batch.target\n",
    "#     preds, new_state = apply(params, state, key, batch.input)\n",
    "#     # return the expectation of the loss wrt the distribution of the targets\n",
    "#     return jnp.sum(optax.softmax_cross_entropy_with_integer_labels(preds, targs)/targs.shape[0]), new_state\n",
    "# key = next(rng)\n",
    "# loss, new_state = _loss_fn(params, state, key, batch)\n",
    "# lfTimer = Timer(stmt=\"_loss_fn(params, state, key, batch)\", globals=globals())\n",
    "# lfTimer.timeit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# a = NamedTuple('A', [('a', int), ('b', int)])(1,2)\n",
    "# b = NamedTuple('A', [('a', int), ('b', int)])(3,3)\n",
    "# s1 = set(a._asdict().items())\n",
    "# s2 = set(b._asdict().items())\n",
    "# s1 ^ s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# trnState = TrainingStore(TrainingState(epoch=0, step=0, batch_n=0, batch=None, metrics=None, last_event=None))\n",
    "# logs = []\n",
    "# def logger(x):\n",
    "#     logs.append(x)\n",
    "#     last = set((logs[-1])._asdict().items())\n",
    "#     curr = set((x)._asdict().items())\n",
    "#     print (last ^ curr)\n",
    "\n",
    "# u4 = trnState.subscribe(lambda x: logger(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# def one_batch(self):\n",
    "#     self.preds = self.model(self.batch[0])\n",
    "#     self.loss = self.loss_func(self.preds, self.batch[1])\n",
    "#     if self.model.training:\n",
    "#         self.loss.backward()\n",
    "#         self.opt.step()\n",
    "#         self.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# class Learner():\n",
    "#     def __init__(self, model, dls, loss_func, lr, cbs, opt_func=optim.SGD): fc.store_attr()\n",
    "\n",
    "#     def one_batch(self):\n",
    "#         self.preds = self.model(self.batch[0])\n",
    "#         self.loss = self.loss_func(self.preds, self.batch[1])\n",
    "#         if self.model.training:\n",
    "#             self.loss.backward()\n",
    "#             self.opt.step()\n",
    "#             self.opt.zero_grad()\n",
    "\n",
    "#     def one_epoch(self, train):\n",
    "#         self.model.train(train)\n",
    "#         self.dl = self.dls.train if train else self.dls.valid\n",
    "#         try:\n",
    "#             self.callback('before_epoch')\n",
    "#             for self.iter,self.batch in enumerate(self.dl):\n",
    "#                 try:\n",
    "#                     self.callback('before_batch')\n",
    "#                     self.one_batch()\n",
    "#                     self.callback('after_batch')\n",
    "#                 except CancelBatchException: pass\n",
    "#             self.callback('after_epoch')\n",
    "#         except CancelEpochException: pass\n",
    "    \n",
    "#     def fit(self, n_epochs):\n",
    "#         self.n_epochs = n_epochs\n",
    "#         self.epochs = range(n_epochs)\n",
    "#         self.opt = self.opt_func(self.model.parameters(), self.lr)\n",
    "#         try:\n",
    "#             self.callback('before_fit')\n",
    "#             for self.epoch in self.epochs:\n",
    "#                 self.one_epoch(True)\n",
    "#                 self.one_epoch(False)\n",
    "#             self.callback('after_fit')\n",
    "#         except CancelFitException: pass\n",
    "\n",
    "#     def callback(self, method_nm): run_cbs(self.cbs, method_nm, self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# #|export\n",
    "# class with_cbs:\n",
    "#     def __init__(self, nm): self.nm = nm\n",
    "#     def __call__(self, f):\n",
    "#         def _f(o, *args, **kwargs):\n",
    "#             try:\n",
    "#                 o.callback(f'before_{self.nm}')\n",
    "#                 f(o, *args, **kwargs)\n",
    "#                 o.callback(f'after_{self.nm}')\n",
    "#             except globals()[f'Cancel{self.nm.title()}Exception']: pass\n",
    "#             finally: o.callback(f'cleanup_{self.nm}')\n",
    "#         return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "# params, state, apply, _ = ms.get()\n",
    "# @jax.jit\n",
    "# def _loss_fn(params, state, batch)-> Tuple[jnp.ndarray, PyTree]:\n",
    "#     bs, *_ = batch.target.shape\n",
    "#     logits, state = apply(params, state, next(rng), batch.input)\n",
    "#     state = {'a':1, 'b':2}\n",
    "#     return jnp.sum(optax.softmax_cross_entropy_with_integer_labels(logits, batch.target)/bs)\n",
    "\n",
    "# def loss_fn(model: ModelStore, batch: Batch) -> float:\n",
    "#     params, state, apply, _ = model.get()\n",
    "#     loss_value =  _loss_fn(params, state, batch)\n",
    "#     new_model = Model(**(m._asdict()|{'state': new_state}))\n",
    "#     model.set(new_model)\n",
    "#     return float(loss_value)\n",
    "\n",
    "# loss_fn(ms, batch)\n",
    "# ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "\n",
    "# def update(model: ModelStore, optimizer: OptimizerStore, batch: Batch)->None:\n",
    "#     m = model.get()\n",
    "#     o = optimizer.get()\n",
    "#     f = partial(loss_fn)(model=model)\n",
    "#     grads = jax.grad(loss_fn)(batch)\n",
    "#     @jax.jit\n",
    "#     def _update():\n",
    "#         updates, new_optState = o.apply(grads, o.state)\n",
    "#         new_model_params = optax.apply_updates(m.params, updates)\n",
    "#         return new_model_params, new_optState\n",
    "#     new_model_params, new_optState = _update()\n",
    "#     new_model = Model(**(m._asdict()|{'params': new_model_params}))\n",
    "#     new_optimizer = Optimizer(**(o._asdict()|{'state': new_optState}))\n",
    "#     model.set(new_model)\n",
    "#     optimizer.set(new_optimizer)\n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# todo: tentar jax.tree_util.Partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# m = ms.get()\n",
    "# o = os.get()\n",
    "# f = partial(loss_fn, model=ms)\n",
    "# grads = jax.grad(f)(batch)\n",
    "# rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "# params, state, apply, _ = ms.get()\n",
    "# def loss_fn():\n",
    "#     loss_value, new_state =  _loss_fn(params, state, batch)\n",
    "    \n",
    "# grads = jax.grad(_loss_fn)(params, state, batch)\n",
    "# grads\n",
    "# update(ms, os, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "\n",
    "# def loss_fn(model: ModelStore, batch: Batch) -> float:\n",
    "#     params, state, apply, _ = model.get()\n",
    "#     @jax.jit\n",
    "#     def _loss(params, state, batch)-> jnp.ndarray:\n",
    "#         bs, *_ = batch.target.shape\n",
    "#         logits, state = (apply)(params, state, next(rng), batch.input)\n",
    "#         return jnp.sum(optax.softmax_cross_entropy_with_integer_labels(logits, batch.target)/bs), state\n",
    "#     loss_value, new_state =  _loss(params, state, batch)\n",
    "#     new_model = Model(**(m._asdict()|{'state': new_state}))\n",
    "#     model.set(new_model)\n",
    "#     return float(loss_value)\n",
    "\n",
    "# loss_fn(ms, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# def get_loss(loss_func, *args): return jax.jit(lambda params: loss_func(get_model(params), *args))\n",
    "# mse_loss = get_loss(mse, xb,tb) \n",
    "# mse_loss, mse_loss(W)\n",
    "# from torch.utils.benchmark import Timer\n",
    "# jax_grad = Timer( stmt=\"jax.grad(mse_loss)\", globals=globals())\n",
    "# jax_grad.timeit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# class TrainingStore(Writable[TrainingState]):\n",
    "\n",
    "#     def emit(self, event: Event):\n",
    "#         self.set(self.value._replace(last_event=event))\n",
    "#     # def __getattr__(self, name): # there  is a bug, I can't fi\n",
    "#     #     if name[:3]=='_s_' : return getattr(self.value, name[3:])\n",
    "#     #     else: return super().__getattr__(name)\n",
    "#     # def __setattr__(self, name, value):\n",
    "#     #     if name[:3]=='_s_' and hasattr(self.value, name[3:]):\n",
    "#     #         self.set(self.value._replace(**{name[3:]: value}))\n",
    "#     #     else: super().__setattr__(name, value)\n",
    "#     def __repr__(self) -> str:\n",
    "#         return f\"{self.__class__.__name__}:\\n{self}\"\n",
    "#     def __str__(self) -> str:\n",
    "#         state = list(self.value._asdict().items())\n",
    "#         cbs = [(f\"{i}:\", v) for i, v in enumerate(self.subscribers)]\n",
    "#         table = list(itertools.zip_longest(list(zip(*state)),list(zip(*cbs))))\n",
    "#         return tabulate(table, headers=['State', 'Calbacks'], tablefmt='grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# def __repr__(self) -> str:\n",
    "#         return f\"{self.__class__.__name__}:\\n{self}\"\n",
    "#     def __str__(self) -> str:\n",
    "#         state = list(self.value._asdict().items())\n",
    "#         state_t = list(zip(*state))\n",
    "#         cbs = [(f\"{i}:\", v) for i, v in enumerate(self.subscribers)]\n",
    "#         cbs_t = list(zip(*cbs))\n",
    "#         table = list(itertools.zip_longest(*state_t,*cbs_t))\n",
    "#         return tabulate(table, headers=['','State','', 'Calbacks'], tablefmt='grid')\n",
    "#     # @property\n",
    "#     # def _(self):\n",
    "#     #     \"\"\"The store value.\"\"\"\n",
    "#     #     return self.value\n",
    "#     # @_.setter\n",
    "#     # def _(self, value: TrainingState):\n",
    "#     #     self.set(value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
