{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: This is the core of the `Reax` lib.\n",
    "output-file: core.html\n",
    "title: core\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_MEM_FRACTION=0.2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in `miniai`, we wil be using the `FashionMnist` Dataset for demonstration.   `Reax` is not intended to be a complete library, the `data` module is just a copy from [miniai]() to make it work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from reax.data import DataLoaders, Batch, Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(input=Array[500, 784] n=392000 x∈[-0.800, 2.057] μ=0.011 σ=1.006 gpu:0, target=Array[500] i32 x∈[0, 9] μ=4.402 σ=2.838 gpu:0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XMEAN,XSTD, BATCH_SIZE, NUM_CLASSES = 0.28,0.35, 500, 10\n",
    "\n",
    "tfm = transforms.Compose([transforms.PILToTensor(), transforms.Lambda(lambda x: x/255), transforms.Normalize(XMEAN, XSTD), transforms.Lambda(lambda x: torch.flatten(x))])\n",
    "ds = partial(torchvision.datasets.FashionMNIST,root=\"data\",download=True, transform = tfm)\n",
    "train_ds, valid_ds = ds(train=True), ds(train=False)\n",
    "tdl = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "vdl = DataLoader(valid_ds, batch_size=BATCH_SIZE)\n",
    "dls = DataLoaders(tdl, vdl)\n",
    "batch = Batch(*map(jnp.array, next(iter(dls.train))))\n",
    "batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic [Haiku](https://dm-haiku.readthedocs.io/) object to represent a model is a [TransformedWithState](https://dm-haiku.readthedocs.io/en/latest/api.html#transformedwithstate).  It represents a `function` or `module` that has been transformed by a `hk.transform` function.  Here we are using `hk.transform_with_state` which is the superset of the transform functions.  \n",
    "\n",
    "State in the `Haiku` lingo means everything that make your original `Callable` not a pure function.  It is the context or state.  Somoe common `DNN` modules like `batch_norm`can keep some `state` to perform its work.  `State`, `Buffers` and `Context` are common names for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "haiku._src.transform.TransformedWithState"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward(x:jnp.array) ->jnp.ndarray:\n",
    "  return hk.nets.MLP(output_sizes=[50,NUM_CLASSES])(x) # todo: remove NUM_CLASSES dependency\n",
    "network = hk.transform_with_state(forward)\n",
    "type(network)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `Reax`, a [`Model`](https://fredguth.github.io/reax/core.html#model) is an immutable object. [PyTrees](https://jax.readthedocs.io/en/latest/pytrees.html) are JAX datastructures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L28){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Model\n",
       "\n",
       ">      Model (params:Union[jax.Array,numpy.ndarray,Tuple[ForwardRef('PyTree'),..\n",
       ">             .],List[ForwardRef('PyTree')],Dict[Hashable,ForwardRef('PyTree')],\n",
       ">             Mapping[str,Mapping[str,jax.Array]],Iterable[ForwardRef('ArrayTree\n",
       ">             ')],Mapping[Any,ForwardRef('ArrayTree')],NoneType], state:Union[ja\n",
       ">             x.Array,numpy.ndarray,Tuple[ForwardRef('PyTree'),...],List[Forward\n",
       ">             Ref('PyTree')],Dict[Hashable,ForwardRef('PyTree')],Mapping[str,Map\n",
       ">             ping[str,jax.Array]],Iterable[ForwardRef('ArrayTree')],Mapping[Any\n",
       ">             ,ForwardRef('ArrayTree')],NoneType], apply:Callable[...,Tuple[Unio\n",
       ">             n[jax.Array,numpy.ndarray],Union[jax.Array,numpy.ndarray,Tuple[For\n",
       ">             wardRef('PyTree'),...],List[ForwardRef('PyTree')],Dict[Hashable,Fo\n",
       ">             rwardRef('PyTree')],Mapping[str,Mapping[str,jax.Array]],Iterable[F\n",
       ">             orwardRef('ArrayTree')],Mapping[Any,ForwardRef('ArrayTree')],NoneT\n",
       ">             ype]]], input_shape:Tuple[int,...])"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L28){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Model\n",
       "\n",
       ">      Model (params:Union[jax.Array,numpy.ndarray,Tuple[ForwardRef('PyTree'),..\n",
       ">             .],List[ForwardRef('PyTree')],Dict[Hashable,ForwardRef('PyTree')],\n",
       ">             Mapping[str,Mapping[str,jax.Array]],Iterable[ForwardRef('ArrayTree\n",
       ">             ')],Mapping[Any,ForwardRef('ArrayTree')],NoneType], state:Union[ja\n",
       ">             x.Array,numpy.ndarray,Tuple[ForwardRef('PyTree'),...],List[Forward\n",
       ">             Ref('PyTree')],Dict[Hashable,ForwardRef('PyTree')],Mapping[str,Map\n",
       ">             ping[str,jax.Array]],Iterable[ForwardRef('ArrayTree')],Mapping[Any\n",
       ">             ,ForwardRef('ArrayTree')],NoneType], apply:Callable[...,Tuple[Unio\n",
       ">             n[jax.Array,numpy.ndarray],Union[jax.Array,numpy.ndarray,Tuple[For\n",
       ">             wardRef('PyTree'),...],List[ForwardRef('PyTree')],Dict[Hashable,Fo\n",
       ">             rwardRef('PyTree')],Mapping[str,Mapping[str,jax.Array]],Iterable[F\n",
       ">             orwardRef('ArrayTree')],Mapping[Any,ForwardRef('ArrayTree')],NoneT\n",
       ">             ype]]], input_shape:Tuple[int,...])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(params={'mlp/~/linear_0': {'b': Array[50] \u001b[38;2;127;127;127mall_zeros\u001b[0m gpu:0, 'w': Array[784, 50] n=39200 x∈[-0.071, 0.071] μ=0.000 σ=0.032 gpu:0}, 'mlp/~/linear_1': {'b': Array[10] \u001b[38;2;127;127;127mall_zeros\u001b[0m gpu:0 [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], 'w': Array[50, 10] n=500 x∈[-0.276, 0.270] μ=-0.001 σ=0.121 gpu:0}}, state={}, apply=<function transform_with_state.<locals>.apply_fn at 0x7f41486c1d30>, input_shape=(500, 784))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Model.from_haiku(transformed=network, x=batch.input)\n",
    "m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep us sane and improve the model representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model:\n",
       "+---------------------------------------------+---------+\n",
       "| Params                                      | State   |\n",
       "+=============================================+=========+\n",
       "| mlp/~/linear_0:                             | {}      |\n",
       "|   b: all_zeros                              |         |\n",
       "|   w: x∈[-0.071, 0.071] μ=-9.844e-05 σ=0.032 |         |\n",
       "| mlp/~/linear_1:                             |         |\n",
       "|   b: all_zeros                              |         |\n",
       "|   w: x∈[-0.275, 0.279] μ=-0.002 σ=0.123     |         |\n",
       "+---------------------------------------------+---------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Model.from_haiku(transformed=network, x=batch.input)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "| Input        | Module                  | Module params   | Output      |   Param count |\n",
      "+==============+=========================+=================+=============+===============+\n",
      "| f32[500,784] | mlp (MLP)               |                 | f32[500,10] |        39,760 |\n",
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "| f32[500,784] | mlp/~/linear_0 (Linear) | w: f32[784,50]  | f32[500,50] |        39,250 |\n",
      "|              |  └ mlp (MLP)            | b: f32[50]      |             |               |\n",
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "| f32[500,50]  | mlp/~/linear_1 (Linear) | w: f32[50,10]   | f32[500,10] |           510 |\n",
      "|              |  └ mlp (MLP)            | b: f32[10]      |             |               |\n",
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "+---------------------------------------------+---------+\n",
      "| Params                                      | State   |\n",
      "+=============================================+=========+\n",
      "| mlp/~/linear_0:                             | {}      |\n",
      "|   b: all_zeros                              |         |\n",
      "|   w: x∈[-0.071, 0.071] μ=-9.844e-05 σ=0.032 |         |\n",
      "| mlp/~/linear_1:                             |         |\n",
      "|   b: all_zeros                              |         |\n",
      "|   w: x∈[-0.275, 0.279] μ=-0.002 σ=0.123     |         |\n",
      "+---------------------------------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Reactivity (Model Store)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we will start to play with reactivity.  In `fastai` (also in Keras, vanilla PyTorch, etc) there is the concept of `Callbacks`.  It is the way to be notified when something of interest happens. \n",
    "\n",
    "> Don't nudge me, let me __call you back__ when I have something for you!\n",
    "\n",
    "In general, you will need a callback only during training, after all, it is when your `things` change.  The model, the hyperparameters, the metrics, etc.\n",
    "\n",
    "The __fastai/miniai__ [`Learner`](https://fredguth.github.io/reax/core.html#learner) is an `Observable` and you can hold multiple callbacks. Every callback keep its state in the Learner object. You can have callbacks for metrics, for logging and saving the training process... callbacks that depend on other callbacks! That is why there is that ... shall I say... __ugly__ `order` property in the `Callback`class.\n",
    "\n",
    "`Reax` is just an experiment on how to handle this reactivity in another way.  Maybe it will prove itself too bloated... or not. I decided to do it in `JAX/Haiku` to force a `functional programming` perspective.\n",
    "\n",
    "The basic abstraction in  `Reax` are `stores`, observables that hold any value. We could have used [RxPy] which is an incredible package. But its superpowers may be too much for what we need. That is why I took inspiration from the `Svelte` JS framework to create `stores` (it became its own package, [Sveltish](https://fredguth.github.io/sveltish))."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [`ModelStore`](https://fredguth.github.io/reax/core.html#modelstore) is just a [`Writable`](https://fredguth.github.io/reax/stores.html#writable) store that holds values of type [`Model`](https://fredguth.github.io/reax/core.html#model). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L71){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelStore\n",
       "\n",
       ">      ModelStore (initial_value:__main__.Model)\n",
       "\n",
       "A Model store. Custom Writable store\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| initial_value | Model | Initial value of the store |\n",
       "| **Returns** | **None** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L71){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelStore\n",
       "\n",
       ">      ModelStore (initial_value:__main__.Model)\n",
       "\n",
       "A Model store. Custom Writable store\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| initial_value | Model | Initial value of the store |\n",
       "| **Returns** | **None** |  |"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ModelStore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving the ModelStore representation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also may improve its representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelStore:\n",
       "+---------------------------------------------+---------+-------------+\n",
       "| Params                                      | State   | Callbacks   |\n",
       "+=============================================+=========+=============+\n",
       "| mlp/~/linear_0:                             | {}      | []          |\n",
       "|   b: all_zeros                              |         |             |\n",
       "|   w: x∈[-0.071, 0.071] μ=-9.844e-05 σ=0.032 |         |             |\n",
       "| mlp/~/linear_1:                             |         |             |\n",
       "|   b: all_zeros                              |         |             |\n",
       "|   w: x∈[-0.275, 0.279] μ=-0.002 σ=0.123     |         |             |\n",
       "+---------------------------------------------+---------+-------------+"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms = ModelStore(m)\n",
    "ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "| Input        | Module                  | Module params   | Output      |   Param count |\n",
      "+==============+=========================+=================+=============+===============+\n",
      "| f32[500,784] | mlp (MLP)               |                 | f32[500,10] |        39,760 |\n",
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "| f32[500,784] | mlp/~/linear_0 (Linear) | w: f32[784,50]  | f32[500,50] |        39,250 |\n",
      "|              |  └ mlp (MLP)            | b: f32[50]      |             |               |\n",
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "| f32[500,50]  | mlp/~/linear_1 (Linear) | w: f32[50,10]   | f32[500,10] |           510 |\n",
      "|              |  └ mlp (MLP)            | b: f32[10]      |             |               |\n",
      "+--------------+-------------------------+-----------------+-------------+---------------+\n",
      "+---------------------------------------------+---------+-------------+\n",
      "| Params                                      | State   | Callbacks   |\n",
      "+=============================================+=========+=============+\n",
      "| mlp/~/linear_0:                             | {}      | []          |\n",
      "|   b: all_zeros                              |         |             |\n",
      "|   w: x∈[-0.071, 0.071] μ=-9.844e-05 σ=0.032 |         |             |\n",
      "| mlp/~/linear_1:                             |         |             |\n",
      "|   b: all_zeros                              |         |             |\n",
      "|   w: x∈[-0.275, 0.279] μ=-0.002 σ=0.123     |         |             |\n",
      "+---------------------------------------------+---------+-------------+\n"
     ]
    }
   ],
   "source": [
    "print(ms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `callback` is any `Callable` that you pass on `subscribe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: callback 1\n"
     ]
    }
   ],
   "source": [
    "u1 = ms.subscribe(lambda x: print(\"1: callback 1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A change in the store value, triggers all callbacks subscribed to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: callback 1\n"
     ]
    }
   ],
   "source": [
    "m = ms.get()\n",
    "ms.set(Model(**(m._asdict()|{\"state\": {'a': 1, 'b': 2}})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can have different `stores` for different things.  For example, this is a simpler one to deal with the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L103){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Optimizer\n",
       "\n",
       ">      Optimizer (state:Union[jax.Array,Iterable[ForwardRef('ArrayTree')],Mappin\n",
       ">                 g[Any,ForwardRef('ArrayTree')]], apply:Callable)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L103){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Optimizer\n",
       "\n",
       ">      Optimizer (state:Union[jax.Array,Iterable[ForwardRef('ArrayTree')],Mappin\n",
       ">                 g[Any,ForwardRef('ArrayTree')]], apply:Callable)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(Optimizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, we will use [Optax](https://optax.readthedocs.io/), which is a good companion for `Haiku`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Optimizer(state=(EmptyState(), EmptyState()), apply=<function chain.<locals>.update_fn at 0x7f41484f4280>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_tfm = optax.sgd(1e-3)\n",
    "apply = grad_tfm.update\n",
    "optState = grad_tfm.init(m.params) # you initialize the optimizer with the model params\n",
    "optimizer = Optimizer(state=optState, apply=apply)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "callback 2: Optimizer(state=(EmptyState(), EmptyState()), apply=<function chain.<locals>.update_fn at 0x7f41484f4280>)\n"
     ]
    }
   ],
   "source": [
    "os= OptimizerStore(optimizer)\n",
    "u2 = os.subscribe(lambda x: print(f\"callback 2: {x}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "callback 2: Optimizer(state=(ScaleByAdamState(count=Array i32 gpu:0 0, mu={'mlp/~/linear_0': {'b': Array[50] all_zeros gpu:0, 'w': Array[784, 50] all_zeros gpu:0}, 'mlp/~/linear_1': {'b': Array[10] all_zeros gpu:0 [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], 'w': Array[50, 10] all_zeros gpu:0}}, nu={'mlp/~/linear_0': {'b': Array[50] all_zeros gpu:0, 'w': Array[784, 50] all_zeros gpu:0}, 'mlp/~/linear_1': {'b': Array[10] all_zeros gpu:0 [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], 'w': Array[50, 10] all_zeros gpu:0}}), EmptyState()), apply=<function chain.<locals>.update_fn at 0x7f41484f4ee0>)\n"
     ]
    }
   ],
   "source": [
    "grad_tf2 = optax.adam(1e-4)\n",
    "optState2 = grad_tf2.init(m.params)\n",
    "os.set(Optimizer(state=optState2, apply=grad_tf2.update))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up... you should remember to unsubscribe when you are done with a store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u1(), u2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m = Model.from_haiku(transformed=network, x=batch.input)\n",
    "ms = ModelStore(m)\n",
    "u1 = ms.subscribe(lambda x: print(f\"cb 1:\\n{x}\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we arrived at the Training, the  `core` of the `core`  ```¯\\_(ツ)_/¯```\n",
    "\n",
    "Here is where we will most need callbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in `fastai`, we create a [`Learner`](https://fredguth.github.io/reax/core.html#learner) class that will deal with the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L111){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Learner\n",
       "\n",
       ">      Learner (model:__main__.ModelStore, dls:reax.data.DataLoaders, loss_func:\n",
       ">               Callable[[Union[jax.Array,numpy.ndarray],Union[jax.Array,numpy.n\n",
       ">               darray]],Union[jax.Array,numpy.ndarray]],\n",
       ">               optimizer:reax.stores.Writable[__main__.Optimizer])\n",
       "\n",
       "Basic class for handling the training loop."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L111){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Learner\n",
       "\n",
       ">      Learner (model:__main__.ModelStore, dls:reax.data.DataLoaders, loss_func:\n",
       ">               Callable[[Union[jax.Array,numpy.ndarray],Union[jax.Array,numpy.n\n",
       ">               darray]],Union[jax.Array,numpy.ndarray]],\n",
       ">               optimizer:reax.stores.Writable[__main__.Optimizer])\n",
       "\n",
       "Basic class for handling the training loop."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(Learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner:\n",
       "+-----------------+-----------------+-----------------+-----------------+\n",
       "|           Model |     DataLoaders |          LossFn |       Optimizer |\n",
       "+=================+=================+=================+=================+\n",
       "| 139918362578752 | 139918365725360 | 139922468264256 | 139918362655424 |\n",
       "+-----------------+-----------------+-----------------+-----------------+"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner = Learner(model=ms, dls=dls, loss_func=optax.softmax_cross_entropy_with_integer_labels, optimizer=os)\n",
    "learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learner itself, is not a store, but holds different stores for different aspects of the training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a [`ModelStore`](https://fredguth.github.io/reax/core.html#modelstore), an `OptimizerStore`... it is only missing the most important thing we want to __observe__... the training loop itself. We need a [`TrainingStore`](https://fredguth.github.io/reax/core.html#trainingstore).\n",
    "\n",
    "But for that... let's first examine what we need.  Let's take a look in the __training loop__:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Fit`: the training Loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# pseudo-code\n",
    "\n",
    "def fit(epochs: int)->None:\n",
    "    '''Train the model for a number of epochs.'''\n",
    "    # before fit\n",
    "    for epoch in range(epochs):\n",
    "        # is_training\n",
    "        one_epoch(dls.train) # train for one epoch\n",
    "        # is_validating\n",
    "        one_epoch(dls.valid) # validate for one epoch\n",
    "        # should halt epochs?\n",
    "    # after fit\n",
    "\n",
    "def one_epoch(dl)->None:\n",
    "    '''Train or validate for one epoch.'''\n",
    "    # before epoch\n",
    "    for batch_n, batch in enumerate(dl): \n",
    "        one_batch(batch_n, batch)\n",
    "        # should halt batches?\n",
    "    # after epoch\n",
    "\n",
    "def one_batch(batch_n: int, batch: Batch)->None:\n",
    "    '''Train or validate for one batch.'''\n",
    "    # before batch\n",
    "    predict(...) # preds\n",
    "    evaluate(...)# loss\n",
    "    update model(...) if is_training\n",
    "    # after batch\n",
    "````"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our [`TrainingStore`](https://fredguth.github.io/reax/core.html#trainingstore) shall tell us where we are in the training loop and some information relevant at this point.\n",
    "\n",
    ">  I am `training`, `epoch` 5, `iteration` 345, after `evaluate` with certain `current loss`.\n",
    "\n",
    "\n",
    "Another aspect is that it seems it should be a [`Readable`](https://fredguth.github.io/reax/stores.html#readable) store, afterall, we don't want any callback being able to change information like:\n",
    "`in which batch of which epoch am I?`\n",
    "\n",
    "Exceptionally, we want to tell the [`TrainingStore`](https://fredguth.github.io/reax/core.html#trainingstore) to halt.\n",
    "\n",
    "Let's start with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L123){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TrainingState\n",
       "\n",
       ">      TrainingState (epochs:int, epoch:int, step:int, iter:int,\n",
       ">                     batch:Optional[reax.data.Batch], last:Dict=None,\n",
       ">                     is_running:bool=False, is_training:bool=False,\n",
       ">                     is_validating:bool=False, should_halt:bool=False)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L123){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TrainingState\n",
       "\n",
       ">      TrainingState (epochs:int, epoch:int, step:int, iter:int,\n",
       ">                     batch:Optional[reax.data.Batch], last:Dict=None,\n",
       ">                     is_running:bool=False, is_training:bool=False,\n",
       ">                     is_validating:bool=False, should_halt:bool=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(TrainingState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingState:\n",
       "-------------  -----\n",
       "epochs             0\n",
       "epoch              0\n",
       "step               0\n",
       "iter               0\n",
       "batch\n",
       "last\n",
       "is_running     False\n",
       "is_training    False\n",
       "is_validating  False\n",
       "should_halt    False\n",
       "-------------  -----"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = TrainingState(epochs=0, epoch=0, step=0, iter=0, batch=None)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L148){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TrainingStore\n",
       "\n",
       ">      TrainingStore (initial_value:T, start:Notifier)\n",
       "\n",
       "A store that keeps tracking of the training loop state\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| initial_value | T | initial value of the store |\n",
       "| start | Notifier | function called when the first subscriber is added |\n",
       "| **Returns** | **None** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fredguth/reax/blob/main/reax/core.py#L148){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TrainingStore\n",
       "\n",
       ">      TrainingStore (initial_value:T, start:Notifier)\n",
       "\n",
       "A store that keeps tracking of the training loop state\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| initial_value | T | initial value of the store |\n",
       "| start | Notifier | function called when the first subscriber is added |\n",
       "| **Returns** | **None** |  |"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(TrainingStore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TrainingStore representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+----+------+\n",
      "|    |   H1 |    |   H2 |\n",
      "+====+======+====+======+\n",
      "| A  |    1 | D  |    4 |\n",
      "+----+------+----+------+\n",
      "| B  |    2 | E  |    5 |\n",
      "+----+------+----+------+\n",
      "| C  |    3 |    |      |\n",
      "+----+------+----+------+\n"
     ]
    }
   ],
   "source": [
    "# a = [(\"A\", \"B\", \"C\"), (1,2,3)]\n",
    "# b = [(\"D\", \"E\", None), (4,5,None)]\n",
    "a = [(\"A\", 1), [\"B\", 2], [\"C\", 3]]\n",
    "b = [[\"D\", 4], [\"E\", 5]]\n",
    "c = list(zip(*a))\n",
    "d = list(zip(*b))\n",
    "table = list(itertools.zip_longest(*c,*d))\n",
    "print(tabulate(table, headers=['','H1','', \"H2\"], tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|    |   H1 |\n",
      "+====+======+\n",
      "| A  |    1 |\n",
      "+----+------+\n",
      "| B  |    2 |\n",
      "+----+------+\n",
      "| C  |    3 |\n",
      "+----+------+\n"
     ]
    }
   ],
   "source": [
    "a = [[\"A\", 1], [\"B\", 2], [\"C\", 3]]\n",
    "b = []\n",
    "c = list(zip(*a))\n",
    "d = list(zip(*b))\n",
    "table = list(itertools.zip_longest(*c,*d))\n",
    "print(tabulate(table, headers=['','H1','', \"H2\"], tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+----+---------------------------------------+\n",
      "|             |    H1 |    | H2                                    |\n",
      "+=============+=======+====+=======================================+\n",
      "| epoch       |     0 | 0: | <function <lambda> at 0x7f414849e670> |\n",
      "+-------------+-------+----+---------------------------------------+\n",
      "| step        |     0 |    |                                       |\n",
      "+-------------+-------+----+---------------------------------------+\n",
      "| batch_n     |     0 |    |                                       |\n",
      "+-------------+-------+----+---------------------------------------+\n",
      "| batch       |       |    |                                       |\n",
      "+-------------+-------+----+---------------------------------------+\n",
      "| metrics     |       |    |                                       |\n",
      "+-------------+-------+----+---------------------------------------+\n",
      "| last_event  |       |    |                                       |\n",
      "+-------------+-------+----+---------------------------------------+\n",
      "| is_training | False |    |                                       |\n",
      "+-------------+-------+----+---------------------------------------+\n",
      "| should_halt | False |    |                                       |\n",
      "+-------------+-------+----+---------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "a = [('epoch', 0), ('step', 0), ('batch_n', 0), ('batch', None), ('metrics', None), ('last_event', None), ('is_training', False), ('should_halt', False)]\n",
    "b = [('0:', lambda:None)]\n",
    "c = list(zip(*a))\n",
    "d = list(zip(*b))\n",
    "table = list(itertools.zip_longest(*c,*d))\n",
    "print(tabulate(table, headers=['','H1','', \"H2\"], tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "callback 4:\n",
      " -------------  -----\n",
      "epochs             0\n",
      "epoch              0\n",
      "step               0\n",
      "iter               0\n",
      "batch\n",
      "last\n",
      "is_running     False\n",
      "is_training    False\n",
      "is_validating  False\n",
      "should_halt    False\n",
      "-------------  -----\n"
     ]
    }
   ],
   "source": [
    "ts = TrainingStore(t, lambda x:None)\n",
    "u4 = ts.subscribe(lambda x: print(f\"callback 4:\\n {x}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+----+---------------------------------------+\n",
      "|               |   State |    | Calbacks                              |\n",
      "+===============+=========+====+=======================================+\n",
      "| epochs        |       0 | 0: | <function <lambda> at 0x7f41484a6700> |\n",
      "+---------------+---------+----+---------------------------------------+\n",
      "| epoch         |       0 |    |                                       |\n",
      "+---------------+---------+----+---------------------------------------+\n",
      "| step          |       0 |    |                                       |\n",
      "+---------------+---------+----+---------------------------------------+\n",
      "| iter          |       0 |    |                                       |\n",
      "+---------------+---------+----+---------------------------------------+\n",
      "| batch         |         |    |                                       |\n",
      "+---------------+---------+----+---------------------------------------+\n",
      "| last          |         |    |                                       |\n",
      "+---------------+---------+----+---------------------------------------+\n",
      "| is_running    |   False |    |                                       |\n",
      "+---------------+---------+----+---------------------------------------+\n",
      "| is_training   |   False |    |                                       |\n",
      "+---------------+---------+----+---------------------------------------+\n",
      "| is_validating |   False |    |                                       |\n",
      "+---------------+---------+----+---------------------------------------+\n",
      "| should_halt   |   False |    |                                       |\n",
      "+---------------+---------+----+---------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "callback: 0\n",
      "callback: 1\n",
      "callback: 2\n",
      "callback: 3\n",
      "callback: 4\n",
      "callback: 5\n",
      "callback: 6\n",
      "callback: 7\n",
      "callback: 8\n",
      "callback: 9\n",
      "callback: 10\n",
      "callback: 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainingStore:\n",
       "+---------------+---------+-----+---------------------------------------+\n",
       "|               |   State |     | Calbacks                              |\n",
       "+===============+=========+=====+=======================================+\n",
       "| epochs        |       0 | 0:  | <function <lambda> at 0x7f41484ad040> |\n",
       "+---------------+---------+-----+---------------------------------------+\n",
       "| epoch         |       0 | 1:  | <function <lambda> at 0x7f41484a6a60> |\n",
       "+---------------+---------+-----+---------------------------------------+\n",
       "| step          |       0 | 2:  | <function <lambda> at 0x7f41484ad280> |\n",
       "+---------------+---------+-----+---------------------------------------+\n",
       "| iter          |       0 | 3:  | <function <lambda> at 0x7f41484a6ca0> |\n",
       "+---------------+---------+-----+---------------------------------------+\n",
       "| batch         |         | 4:  | <function <lambda> at 0x7f41484a64c0> |\n",
       "+---------------+---------+-----+---------------------------------------+\n",
       "| last          |         | 5:  | <function <lambda> at 0x7f41484ad4c0> |\n",
       "+---------------+---------+-----+---------------------------------------+\n",
       "| is_running    |   False | 6:  | <function <lambda> at 0x7f41484a6ee0> |\n",
       "+---------------+---------+-----+---------------------------------------+\n",
       "| is_training   |   False | 7:  | <function <lambda> at 0x7f41484a6700> |\n",
       "+---------------+---------+-----+---------------------------------------+\n",
       "| is_validating |   False | 8:  | <function <lambda> at 0x7f41484a6940> |\n",
       "+---------------+---------+-----+---------------------------------------+\n",
       "| should_halt   |   False | 9:  | <function <lambda> at 0x7f41484ad160> |\n",
       "+---------------+---------+-----+---------------------------------------+\n",
       "|               |         | 10: | <function <lambda> at 0x7f41484a6b80> |\n",
       "+---------------+---------+-----+---------------------------------------+\n",
       "|               |         | 11: | <function <lambda> at 0x7f41484ad3a0> |\n",
       "+---------------+---------+-----+---------------------------------------+\n",
       "|               |         | 12: | <function <lambda> at 0x7f41484a6dc0> |\n",
       "+---------------+---------+-----+---------------------------------------+"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsubs = []\n",
    "for i in range(12):\n",
    "    u = ts.subscribe(lambda x: print(f\"callback: {i}\"))\n",
    "    unsubs.append(u)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for u in unsubs: u()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# class TrainingStore(Writable[TrainingState]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# @fc.patch\n",
    "# def fit(self:Learner, n_epochs, trnState: TrainingState):\n",
    "#     \"Fit the model for `n_epochs` using batches from `dls`\"\n",
    "#     trnState.emit(Event(id=\"before_fit\", payload=None))\n",
    "#     for epoch in range(n_epochs):\n",
    "#         self.one_epoch(is_training=True, trnState=trnState)\n",
    "#         self.one_epoch(is_training=False, trnState=trnState)\n",
    "#         if (trnState.get().should_halt): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# training = TrainingStore(TrainingState(epoch=0, step=0, batch_n=0, batch=None, metrics=None, last_event=None))\n",
    "# u3 = training.subscribe(lambda x: print(f\"3:\\n {x}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# @fc.patch\n",
    "# def fit(self:Learner, n_epochs, trnState: TrainingState):\n",
    "#     \"Fit the model for `n_epochs` using batches from `dls`\"\n",
    "#     trnState.emit(Event(id=\"before_fit\", payload=None))\n",
    "#     for epoch in range(n_epochs):\n",
    "#         self.one_epoch(is_training=True, trnState=trnState)\n",
    "#         self.one_epoch(is_training=False, trnState=trnState)\n",
    "#         if (trnState.get().should_halt): break\n",
    "\n",
    "# @fc.patch\n",
    "# def one_epoch(self:Learner, is_training: bool, trnState: TrainingState):\n",
    "#     a = 1\n",
    "#     # print(f\"one_epoch: is_training={is_training}\")\n",
    "#     # print(trnState)\n",
    "#     # trnState._s_is_training = is_training\n",
    "#     # self.dl = self.dls.train if is_training else self.dls.valid\n",
    "#     # trnState.emit(Event(id=f\"before_epoch\", payload=trnState._s_epoch))\n",
    "#     # for batch_n, batch in enumerate(self.dl):\n",
    "#     #     trnState._s_batch_n, trnState._s_batch  = batch_n, batch\n",
    "#     #     # self.one_batch(trnState=trnState)\n",
    "#     #     if (trnState._s_should_halt): break\n",
    "#     # trnState.emit(Event(id=f\"after_epoch\", payload=trnState._s_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# params, state, apply, _ = ms.get()\n",
    "# rng = hk.PRNGSequence(42) # random number generator\n",
    "# @jax.jit\n",
    "# def _predict(params, state, key, batch) -> Tensor:\n",
    "#     logits, new_state = apply(params, state, key, batch.input)\n",
    "#     return jnp.argmax (logits, axis=-1), new_state\n",
    "# key = next(rng)\n",
    "# _predict(params, state, key, batch)\n",
    "# @jax.jit\n",
    "# def _evaluate(params, state, key, batch) -> Tensor:\n",
    "#     preds, _ = _predict(params, state, key, batch)\n",
    "#     return jnp.mean(preds == batch.target)\n",
    "# from torch.utils.benchmark import Timer\n",
    "# evTimer = Timer(stmt=\"_evaluate(params, state, key, batch)\", globals=globals())\n",
    "# evTimer.timeit(1000)\n",
    "# rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "\n",
    "# def evaluate(model: ModelStore, batch: Batch) -> Tensor:\n",
    "#     params, state, apply, _ = model.get()\n",
    "#     key = next(rng)\n",
    "#     return _evaluate(params, state, key, batch)\n",
    "# evaluate(ms, batch)\n",
    "# @jax.jit\n",
    "# def _loss_fn(params, state, key, batch)-> jnp.ndarray:\n",
    "#     targs = batch.target\n",
    "#     preds, new_state = apply(params, state, key, batch.input)\n",
    "#     # return the expectation of the loss wrt the distribution of the targets\n",
    "#     return jnp.sum(optax.softmax_cross_entropy_with_integer_labels(preds, targs)/targs.shape[0]), new_state\n",
    "# key = next(rng)\n",
    "# loss, new_state = _loss_fn(params, state, key, batch)\n",
    "# lfTimer = Timer(stmt=\"_loss_fn(params, state, key, batch)\", globals=globals())\n",
    "# lfTimer.timeit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# a = NamedTuple('A', [('a', int), ('b', int)])(1,2)\n",
    "# b = NamedTuple('A', [('a', int), ('b', int)])(3,3)\n",
    "# s1 = set(a._asdict().items())\n",
    "# s2 = set(b._asdict().items())\n",
    "# s1 ^ s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# trnState = TrainingStore(TrainingState(epoch=0, step=0, batch_n=0, batch=None, metrics=None, last_event=None))\n",
    "# logs = []\n",
    "# def logger(x):\n",
    "#     logs.append(x)\n",
    "#     last = set((logs[-1])._asdict().items())\n",
    "#     curr = set((x)._asdict().items())\n",
    "#     print (last ^ curr)\n",
    "\n",
    "# u4 = trnState.subscribe(lambda x: logger(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# def one_batch(self):\n",
    "#     self.preds = self.model(self.batch[0])\n",
    "#     self.loss = self.loss_func(self.preds, self.batch[1])\n",
    "#     if self.model.training:\n",
    "#         self.loss.backward()\n",
    "#         self.opt.step()\n",
    "#         self.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# class Learner():\n",
    "#     def __init__(self, model, dls, loss_func, lr, cbs, opt_func=optim.SGD): fc.store_attr()\n",
    "\n",
    "#     def one_batch(self):\n",
    "#         self.preds = self.model(self.batch[0])\n",
    "#         self.loss = self.loss_func(self.preds, self.batch[1])\n",
    "#         if self.model.training:\n",
    "#             self.loss.backward()\n",
    "#             self.opt.step()\n",
    "#             self.opt.zero_grad()\n",
    "\n",
    "#     def one_epoch(self, train):\n",
    "#         self.model.train(train)\n",
    "#         self.dl = self.dls.train if train else self.dls.valid\n",
    "#         try:\n",
    "#             self.callback('before_epoch')\n",
    "#             for self.iter,self.batch in enumerate(self.dl):\n",
    "#                 try:\n",
    "#                     self.callback('before_batch')\n",
    "#                     self.one_batch()\n",
    "#                     self.callback('after_batch')\n",
    "#                 except CancelBatchException: pass\n",
    "#             self.callback('after_epoch')\n",
    "#         except CancelEpochException: pass\n",
    "    \n",
    "#     def fit(self, n_epochs):\n",
    "#         self.n_epochs = n_epochs\n",
    "#         self.epochs = range(n_epochs)\n",
    "#         self.opt = self.opt_func(self.model.parameters(), self.lr)\n",
    "#         try:\n",
    "#             self.callback('before_fit')\n",
    "#             for self.epoch in self.epochs:\n",
    "#                 self.one_epoch(True)\n",
    "#                 self.one_epoch(False)\n",
    "#             self.callback('after_fit')\n",
    "#         except CancelFitException: pass\n",
    "\n",
    "#     def callback(self, method_nm): run_cbs(self.cbs, method_nm, self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# #|export\n",
    "# class with_cbs:\n",
    "#     def __init__(self, nm): self.nm = nm\n",
    "#     def __call__(self, f):\n",
    "#         def _f(o, *args, **kwargs):\n",
    "#             try:\n",
    "#                 o.callback(f'before_{self.nm}')\n",
    "#                 f(o, *args, **kwargs)\n",
    "#                 o.callback(f'after_{self.nm}')\n",
    "#             except globals()[f'Cancel{self.nm.title()}Exception']: pass\n",
    "#             finally: o.callback(f'cleanup_{self.nm}')\n",
    "#         return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "# params, state, apply, _ = ms.get()\n",
    "# @jax.jit\n",
    "# def _loss_fn(params, state, batch)-> Tuple[jnp.ndarray, PyTree]:\n",
    "#     bs, *_ = batch.target.shape\n",
    "#     logits, state = apply(params, state, next(rng), batch.input)\n",
    "#     state = {'a':1, 'b':2}\n",
    "#     return jnp.sum(optax.softmax_cross_entropy_with_integer_labels(logits, batch.target)/bs)\n",
    "\n",
    "# def loss_fn(model: ModelStore, batch: Batch) -> float:\n",
    "#     params, state, apply, _ = model.get()\n",
    "#     loss_value =  _loss_fn(params, state, batch)\n",
    "#     new_model = Model(**(m._asdict()|{'state': new_state}))\n",
    "#     model.set(new_model)\n",
    "#     return float(loss_value)\n",
    "\n",
    "# loss_fn(ms, batch)\n",
    "# ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "\n",
    "# def update(model: ModelStore, optimizer: OptimizerStore, batch: Batch)->None:\n",
    "#     m = model.get()\n",
    "#     o = optimizer.get()\n",
    "#     f = partial(loss_fn)(model=model)\n",
    "#     grads = jax.grad(loss_fn)(batch)\n",
    "#     @jax.jit\n",
    "#     def _update():\n",
    "#         updates, new_optState = o.apply(grads, o.state)\n",
    "#         new_model_params = optax.apply_updates(m.params, updates)\n",
    "#         return new_model_params, new_optState\n",
    "#     new_model_params, new_optState = _update()\n",
    "#     new_model = Model(**(m._asdict()|{'params': new_model_params}))\n",
    "#     new_optimizer = Optimizer(**(o._asdict()|{'state': new_optState}))\n",
    "#     model.set(new_model)\n",
    "#     optimizer.set(new_optimizer)\n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# todo: tentar jax.tree_util.Partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# m = ms.get()\n",
    "# o = os.get()\n",
    "# f = partial(loss_fn, model=ms)\n",
    "# grads = jax.grad(f)(batch)\n",
    "# rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "# params, state, apply, _ = ms.get()\n",
    "# def loss_fn():\n",
    "#     loss_value, new_state =  _loss_fn(params, state, batch)\n",
    "    \n",
    "# grads = jax.grad(_loss_fn)(params, state, batch)\n",
    "# grads\n",
    "# update(ms, os, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "\n",
    "# def loss_fn(model: ModelStore, batch: Batch) -> float:\n",
    "#     params, state, apply, _ = model.get()\n",
    "#     @jax.jit\n",
    "#     def _loss(params, state, batch)-> jnp.ndarray:\n",
    "#         bs, *_ = batch.target.shape\n",
    "#         logits, state = (apply)(params, state, next(rng), batch.input)\n",
    "#         return jnp.sum(optax.softmax_cross_entropy_with_integer_labels(logits, batch.target)/bs), state\n",
    "#     loss_value, new_state =  _loss(params, state, batch)\n",
    "#     new_model = Model(**(m._asdict()|{'state': new_state}))\n",
    "#     model.set(new_model)\n",
    "#     return float(loss_value)\n",
    "\n",
    "# loss_fn(ms, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# def get_loss(loss_func, *args): return jax.jit(lambda params: loss_func(get_model(params), *args))\n",
    "# mse_loss = get_loss(mse, xb,tb) \n",
    "# mse_loss, mse_loss(W)\n",
    "# from torch.utils.benchmark import Timer\n",
    "# jax_grad = Timer( stmt=\"jax.grad(mse_loss)\", globals=globals())\n",
    "# jax_grad.timeit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# class TrainingStore(Writable[TrainingState]):\n",
    "\n",
    "#     def emit(self, event: Event):\n",
    "#         self.set(self.value._replace(last_event=event))\n",
    "#     # def __getattr__(self, name): # there  is a bug, I can't fi\n",
    "#     #     if name[:3]=='_s_' : return getattr(self.value, name[3:])\n",
    "#     #     else: return super().__getattr__(name)\n",
    "#     # def __setattr__(self, name, value):\n",
    "#     #     if name[:3]=='_s_' and hasattr(self.value, name[3:]):\n",
    "#     #         self.set(self.value._replace(**{name[3:]: value}))\n",
    "#     #     else: super().__setattr__(name, value)\n",
    "#     def __repr__(self) -> str:\n",
    "#         return f\"{self.__class__.__name__}:\\n{self}\"\n",
    "#     def __str__(self) -> str:\n",
    "#         state = list(self.value._asdict().items())\n",
    "#         cbs = [(f\"{i}:\", v) for i, v in enumerate(self.subscribers)]\n",
    "#         table = list(itertools.zip_longest(list(zip(*state)),list(zip(*cbs))))\n",
    "#         return tabulate(table, headers=['State', 'Calbacks'], tablefmt='grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "language": "python",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# def __repr__(self) -> str:\n",
    "#         return f\"{self.__class__.__name__}:\\n{self}\"\n",
    "#     def __str__(self) -> str:\n",
    "#         state = list(self.value._asdict().items())\n",
    "#         state_t = list(zip(*state))\n",
    "#         cbs = [(f\"{i}:\", v) for i, v in enumerate(self.subscribers)]\n",
    "#         cbs_t = list(zip(*cbs))\n",
    "#         table = list(itertools.zip_longest(*state_t,*cbs_t))\n",
    "#         return tabulate(table, headers=['','State','', 'Calbacks'], tablefmt='grid')\n",
    "#     # @property\n",
    "#     # def _(self):\n",
    "#     #     \"\"\"The store value.\"\"\"\n",
    "#     #     return self.value\n",
    "#     # @_.setter\n",
    "#     # def _(self, value: TrainingState):\n",
    "#     #     self.set(value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
